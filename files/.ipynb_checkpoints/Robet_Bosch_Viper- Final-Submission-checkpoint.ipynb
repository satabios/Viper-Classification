{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mqhvo9EvN4zZ",
    "outputId": "f3cf11a3-2e55-4bd4-83dc-f16e514ec888"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "Kjhx8hHdN6CT",
    "outputId": "6fe246c9-4d3c-42e8-e559-450b99a875c0"
   },
   "outputs": [],
   "source": [
    "# %cd /content/drive/MyDrive/Robert_Bosch/dataset/Test_data/\n",
    "# %ls \n",
    "# # %mkdir -p dataset\n",
    "# !pip install ipdb\n",
    "# # !unzip Test_data.zip -d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CE_loss-epoch=193-valid_acc=0.781.ckpt'\r\n",
      "'eff-ns-b7_focal[Training].ipynb'\r\n",
      " \u001b[0m\u001b[01;34mlightning_logs\u001b[0m/\r\n",
      "'Model Infer.ipynb'\r\n",
      " Robet_Bosch_Viper-Eff-Copy1.ipynb\r\n",
      " Robet_Bosch_Viper-Eff.ipynb\r\n",
      "'Robet_Bosch_Viper- Final-256_CE.ipynb'\r\n",
      "'Robet_Bosch_Viper- Final-256CE.ipynb'\r\n",
      "'Robet_Bosch_Viper- Final-256_CE-without brightness-Copy1.ipynb'\r\n",
      "'Robet_Bosch_Viper- Final-256_CE-without brightness.ipynb'\r\n",
      "'Robet_Bosch_Viper- Final-Copy2.ipynb'\r\n",
      "'Robet_Bosch_Viper- Final.ipynb'\r\n",
      "'Robet_Bosch_Viper- Transforms with dropout.ipynb'\r\n",
      " Robet_Bosch_Viper-Triplet.ipynb\r\n",
      "'Robet_Bosch_Viper- Vanilla.ipynb'\r\n",
      " Sample_Submission.csv\r\n",
      " \u001b[01;34mTest\u001b[0m/\r\n",
      " \u001b[01;34mTrain\u001b[0m/\r\n",
      " \u001b[01;34mVal\u001b[0m/\r\n",
      " \u001b[01;34mwandb\u001b[0m/\r\n",
      " \u001b[01;34mweights\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJJIIJrvOxgn",
    "outputId": "f81e88c2-2258-4f6a-d0c0-4a23c5bb41b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Points:\n",
      "Train: 970 Validate: 4850 Test: 1940\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import ipdb \n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('./')\n",
    "train_test_val = 0\n",
    "dataset = []\n",
    "k_fold = True\n",
    "# folders_to_look = ['Train/','Val/','Test/'] if k_fold==True else ['Train/']\n",
    "classes = [cl.split('/')[1] for cl in glob.glob('Train/'+'/*')] #Class names\n",
    "cls_len = len(glob.glob('Train/'+'/*')) #Number of Classes in the dataset\n",
    "\n",
    "for folder in glob.iglob('*/'):\n",
    "#     if(train_test_val == 0):\n",
    "#         if(folder in folders_to_look):\n",
    "    if(folder == 'Test/'):\n",
    "        \n",
    "        for files in glob.iglob(folder+\"/*.jpg\"):\n",
    "            img_path = files\n",
    "            dataset.append((img_path,-1))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        for classess in glob.glob(folder+'/*'):\n",
    "            for files in glob.iglob(classess+\"/*.jpg\"):\n",
    "                img_path = files\n",
    "                class_id = classes.index(files.split('/')[1])\n",
    "                dataset.append((img_path,class_id))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(dataset,columns=['image_path','class'])\n",
    "# dataset = np.asarray(dataset)\n",
    "train_df, val_df, test_df = df.iloc[:970],df.iloc[970:], df.iloc[970+2910:]\n",
    "print(\"Data Points:\")\n",
    "print(\"Train:\",len(train_df),\"Validate:\",len(val_df),\"Test:\",len(test_df))\n",
    "\n",
    "\n",
    "#Checking for Class Imbalance\n",
    "cls, counts = np.unique(train_df['class'].values, return_counts=True)\n",
    "# print([print(\"class:\",classes[cls[i]],\"counts:\",counts[i]) for i in range(cls_len)])\n",
    "# Hence no class imbalance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    test = True\n",
    "    triplet = False\n",
    "    num_classes = len(classes)\n",
    "    clases = classes\n",
    "    train_batch_size = 8*4 # Reduce if triplet is True, defualt : 8*4*4\n",
    "    val_batch_size = 8*4*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XaqO3MNyaFy",
    "outputId": "3c755ae2-7333-4ae9-b999-d845d7e4a267"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sathya/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "#k-Fold Validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=6)\n",
    "skf.get_n_splits(len(df))\n",
    "fold = 0\n",
    "df['fold'] =0 \n",
    "for train_index, test_index in skf.split(df['image_path'],df['class']):\n",
    "    df['fold'].loc[test_index]=fold\n",
    "    fold+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['human', 'animal', 'truck', 'car', 'airplane']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wzLAAA_Kxjxw"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchcontrib.optim import SWA\n",
    "from pytorch_lightning.metrics import Metric\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "\n",
    "class vdataset(Dataset):\n",
    "    def __init__(self, df, triplet=False, test=False ,transform=None):\n",
    "        self.df = df\n",
    "        self.transforms = transform\n",
    "        self.triplet = triplet\n",
    "        self.test = test\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def read_image(self, image_path):\n",
    "        image = cv2.imread(image_path).astype(np.float32)\n",
    "        image = (image-np.min(image))/(np.max(image)-np.min(image))\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)\n",
    "            image = image['image']\n",
    "        else:\n",
    "            image = np.moveaxis(image,-1,0)\n",
    "        return image\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.df.iloc[idx]\n",
    "        anchor_image_path, anchor_label = data['image_path'], data['class']\n",
    "        anchor_image = self.read_image(anchor_image_path)\n",
    "        \n",
    "        if self.triplet:                  #For Siamese Triplet Learning\n",
    "            if(anchor_label ==1 or anchor_label ==2 or anchor_label ==3):\n",
    "                if(anchor_label ==1):\n",
    "                    p=[0.4,0,0.2,0.2,0.2]\n",
    "                elif(anchor_label ==2):\n",
    "                    p=[0.2,0.2,0,0.4,0.2]\n",
    "                elif(anchor_label ==3):\n",
    "                    p=[0.2,0.2,0.4,0,0.2]\n",
    "\n",
    "                anchor_label_neg =np.random.choice(range(5),size=1,p=p)\n",
    "                negative_index = np.random.choice(train_df[train_df['class']==anchor_label_neg[0]].index)\n",
    "                negative_image_path, negative_label = train_df.iloc[negative_index]\n",
    "                negative_image = self.read_image(negative_image_path)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                \n",
    "                negative_index = np.random.choice(train_df[train_df['class']!=anchor_label].index)\n",
    "                negative_image_path, negative_label = train_df.iloc[negative_index]\n",
    "                negative_image = self.read_image(negative_image_path)\n",
    "\n",
    "\n",
    "            positive_index = np.random.choice(train_df[train_df['class']==anchor_label].index)\n",
    "            positive_image_path, positive_label = train_df.iloc[positive_index]\n",
    "            positive_image = self.read_image(positive_image_path)\n",
    "\n",
    "            return (anchor_image,anchor_label), (positive_image, positive_label),(negative_image, negative_label)\n",
    "        \n",
    "        else:\n",
    "            if self.test:\n",
    "                return anchor_image_path, anchor_image,torch.tensor(anchor_label)\n",
    "            else:\n",
    "                return anchor_image,torch.tensor(anchor_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "SUvaycUw5nZ0",
    "outputId": "5a4c2578-8330-4e8e-e834-af103a5e96d7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "#        A.ShiftScaleRotate(rotate_limit=(-360, 360), shift_limit=(0.1, 0.12), scale_limit=(0.1, 0.12)),\n",
    "       A.HorizontalFlip(p=0.5),\n",
    "       A.Sharpen(alpha=(0.3,0.5), lightness=(0.5, 1.0), always_apply= False, p=0.6) ,\n",
    "       A.Rotate (limit=180),\n",
    "#       A.RandomBrightnessContrast(brightness_limit=0.3,contrast_limit=0.2,p=0.5),\n",
    "#         iaa.Sequential([\n",
    "#         iaa.Canny(alpha=(0.0, 0.6))\n",
    "#              ]).augment_image,\n",
    "#       A.Affine (scale=None, translate_percent=None, translate_px=None, rotate=None, shear=(0,15),\n",
    "#                 interpolation=1, cval=0, cval_mask=0, mode=0, fit_output=False, always_apply=False, p=0.5),\n",
    "#        A.RandomBrightnessContrast(contrast_limit=0.2, always_apply=False, p=0.5),\n",
    "#        A.Perspective(scale=(0.05, 0.1)),\n",
    "#        A.Affine (scale=1,translate_percent=0.1,fit_output=True),\n",
    "       ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "valid_transform = A.Compose(\n",
    "    [\n",
    "       ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_dataset = vdataset(val_df, transform = valid_transform)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8*4*4,\n",
    "                        shuffle=False, num_workers=32)\n",
    "\n",
    "test_dataset = vdataset(test_df, test= config.test, transform = valid_transform)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8*4*4,\n",
    "                        shuffle=False, num_workers=32)\n",
    "\n",
    "if config.test:\n",
    "    \n",
    "    fig, axs = plt.subplots(2,3)\n",
    "    fig.tight_layout()\n",
    "    cls_ind = 0\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            path ,test_sample,cls = test_dataset.__getitem__(190*cls_ind)\n",
    "            axs[i][j].imshow(test_sample[0,:],cmap='gray', aspect='auto')\n",
    "            axs[i][j].set_title(\"Test Class\")\n",
    "            cls_ind+=1\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "\n",
    "    if (config.triplet==True):\n",
    "        #Triplet Visualization\n",
    "\n",
    "        train_dataset_triplet = vdataset(train_df,triplet=True, transform = train_transform)\n",
    "\n",
    "\n",
    "        train_dataloader_triplet = DataLoader(train_dataset_triplet, batch_size=8,\n",
    "                                shuffle=True, num_workers=32)\n",
    "\n",
    "\n",
    "        fig, axs = plt.subplots(5, 3)\n",
    "        fig.tight_layout()\n",
    "        cls_ind = 0\n",
    "        for i in range(5):\n",
    "\n",
    "            (anc,cls),(pos,cls),(neg,neg_cls) = train_dataset_triplet.__getitem__(197*i+1)\n",
    "            axs[i][0].imshow(anc[0,:],cmap='gray',aspect='auto')\n",
    "            axs[i][0].set_title(classes[cls])\n",
    "            axs[i][1].imshow(pos[0,:],cmap='gray', aspect='auto')\n",
    "            axs[i][1].set_title(classes[cls])\n",
    "            axs[i][2].imshow(neg[0,:],cmap='gray', aspect='auto')\n",
    "            axs[i][2].set_title(classes[neg_cls])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        train_dataset = vdataset(train_df,test= config.test, transform = train_transform)\n",
    "\n",
    "\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=8*4*4,\n",
    "                            shuffle=True, num_workers=32)\n",
    "        fig, axs = plt.subplots(2,3)\n",
    "        fig.tight_layout()\n",
    "        cls_ind = 0\n",
    "        for i in range(2):\n",
    "            for j in range(3):\n",
    "                path ,test_sample,cls = train_dataset.__getitem__(190*cls_ind)\n",
    "                axs[i][j].imshow(test_sample[0,:],cmap='gray', aspect='auto')\n",
    "                axs[i][j].set_title(classes[cls])\n",
    "                cls_ind+=1\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lCL6eEUxvdBv",
    "outputId": "e5425e52-188e-4904-89d4-0dc56734b66d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Conv2d: 1-1                            [-1, 8, 96, 96]           216\n",
      "BatchNorm2d: 1-2                       [-1, 8, 96, 96]           16\n",
      "ReLU: 1-3                              [-1, 8, 96, 96]           --\n",
      "Conv2d: 1-4                            [-1, 16, 96, 96]          1,152\n",
      "BatchNorm2d: 1-5                       [-1, 16, 96, 96]          32\n",
      "ReLU: 1-6                              [-1, 16, 96, 96]          --\n",
      "Sequential: 1-7                        [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-1                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-1                  [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-2             [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-3                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-4                  [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-5             [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-6                    [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-2                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-7                  [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-8             [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-9                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-10                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-11            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-12                   [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-3                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-13                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-14            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-15                   [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-16                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-17            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-18                   [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-4                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-19                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-20            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-21                   [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-22                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-23            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-24                   [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-5                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-25                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-26            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-27                   [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-28                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-29            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-30                   [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-6                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-31                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-32            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-33                   [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-34                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-35            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-36                   [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-7                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-37                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-38            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-39                   [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-40                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-41            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-42                   [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-8                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-43                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-44            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-45                   [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-46                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-47            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-48                   [-1, 16, 96, 96]          --\n",
      "Sequential: 1-8                        [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-9                    [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-49                 [-1, 32, 48, 48]          4,608\n",
      "|    |    BatchNorm2d: 3-50            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-51                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-52                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-53            [-1, 32, 48, 48]          64\n",
      "|    |    Sequential: 3-54             [-1, 32, 48, 48]          4,672\n",
      "|    |    ReLU: 3-55                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-10                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-56                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-57            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-58                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-59                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-60            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-61                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-11                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-62                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-63            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-64                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-65                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-66            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-67                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-12                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-68                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-69            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-70                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-71                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-72            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-73                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-13                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-74                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-75            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-76                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-77                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-78            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-79                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-14                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-80                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-81            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-82                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-83                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-84            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-85                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-15                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-86                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-87            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-88                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-89                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-90            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-91                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-16                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-92                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-93            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-94                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-95                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-96            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-97                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-17                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-98                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-99            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-100                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-101                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-102           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-103                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-18                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-104                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-105           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-106                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-107                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-108           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-109                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-19                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-110                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-111           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-112                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-113                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-114           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-115                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-20                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-116                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-117           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-118                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-119                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-120           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-121                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-21                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-122                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-123           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-124                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-125                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-126           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-127                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-22                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-128                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-129           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-130                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-131                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-132           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-133                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-23                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-134                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-135           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-136                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-137                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-138           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-139                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-24                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-140                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-141           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-142                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-143                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-144           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-145                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-25                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-146                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-147           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-148                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-149                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-150           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-151                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-26                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-152                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-153           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-154                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-155                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-156           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-157                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-27                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-158                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-159           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-160                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-161                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-162           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-163                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-28                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-164                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-165           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-166                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-167                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-168           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-169                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-29                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-170                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-171           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-172                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-173                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-174           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-175                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-30                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-176                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-177           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-178                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-179                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-180           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-181                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-31                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-182                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-183           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-184                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-185                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-186           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-187                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-32                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-188                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-189           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-190                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-191                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-192           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-193                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-33                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-194                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-195           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-196                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-197                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-198           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-199                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-34                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-200                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-201           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-202                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-203                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-204           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-205                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-35                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-206                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-207           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-208                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-209                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-210           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-211                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-36                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-212                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-213           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-214                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-215                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-216           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-217                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-37                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-218                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-219           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-220                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-221                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-222           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-223                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-38                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-224                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-225           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-226                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-227                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-228           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-229                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-39                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-230                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-231           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-232                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-233                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-234           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-235                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-40                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-236                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-237           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-238                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-239                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-240           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-241                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-41                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-242                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-243           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-244                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-245                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-246           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-247                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-42                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-248                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-249           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-250                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-251                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-252           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-253                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-43                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-254                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-255           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-256                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-257                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-258           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-259                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-44                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-260                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-261           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-262                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-263                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-264           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-265                  [-1, 32, 48, 48]          --\n",
      "Sequential: 1-9                        [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-45                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-266                [-1, 64, 24, 24]          18,432\n",
      "|    |    BatchNorm2d: 3-267           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-268                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-269                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-270           [-1, 64, 24, 24]          128\n",
      "|    |    Sequential: 3-271            [-1, 64, 24, 24]          18,560\n",
      "|    |    ReLU: 3-272                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-46                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-273                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-274           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-275                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-276                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-277           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-278                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-47                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-279                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-280           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-281                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-282                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-283           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-284                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-48                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-285                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-286           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-287                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-288                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-289           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-290                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-49                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-291                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-292           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-293                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-294                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-295           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-296                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-50                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-297                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-298           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-299                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-300                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-301           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-302                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-51                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-303                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-304           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-305                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-306                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-307           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-308                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-52                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-309                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-310           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-311                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-312                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-313           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-314                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-53                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-315                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-316           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-317                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-318                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-319           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-320                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-54                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-321                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-322           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-323                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-324                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-325           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-326                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-55                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-327                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-328           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-329                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-330                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-331           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-332                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-56                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-333                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-334           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-335                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-336                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-337           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-338                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-57                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-339                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-340           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-341                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-342                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-343           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-344                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-58                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-345                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-346           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-347                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-348                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-349           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-350                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-59                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-351                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-352           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-353                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-354                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-355           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-356                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-60                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-357                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-358           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-359                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-360                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-361           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-362                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-61                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-363                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-364           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-365                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-366                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-367           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-368                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-62                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-369                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-370           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-371                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-372                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-373           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-374                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-63                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-375                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-376           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-377                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-378                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-379           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-380                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-64                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-381                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-382           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-383                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-384                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-385           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-386                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-65                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-387                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-388           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-389                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-390                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-391           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-392                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-66                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-393                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-394           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-395                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-396                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-397           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-398                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-67                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-399                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-400           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-401                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-402                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-403           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-404                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-68                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-405                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-406           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-407                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-408                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-409           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-410                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-69                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-411                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-412           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-413                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-414                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-415           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-416                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-70                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-417                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-418           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-419                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-420                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-421           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-422                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-71                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-423                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-424           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-425                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-426                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-427           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-428                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-72                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-429                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-430           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-431                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-432                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-433           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-434                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-73                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-435                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-436           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-437                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-438                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-439           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-440                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-74                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-441                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-442           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-443                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-444                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-445           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-446                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-75                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-447                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-448           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-449                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-450                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-451           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-452                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-76                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-453                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-454           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-455                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-456                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-457           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-458                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-77                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-459                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-460           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-461                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-462                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-463           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-464                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-78                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-465                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-466           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-467                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-468                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-469           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-470                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-79                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-471                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-472           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-473                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-474                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-475           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-476                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-80                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-477                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-478           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-479                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-480                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-481           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-482                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-81                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-483                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-484           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-485                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-486                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-487           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-488                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-82                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-489                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-490           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-491                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-492                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-493           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-494                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-83                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-495                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-496           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-497                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-498                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-499           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-500                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-84                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-501                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-502           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-503                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-504                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-505           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-506                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-85                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-507                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-508           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-509                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-510                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-511           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-512                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-86                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-513                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-514           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-515                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-516                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-517           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-518                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-87                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-519                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-520           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-521                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-522                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-523           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-524                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-88                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-525                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-526           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-527                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-528                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-529           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-530                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-89                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-531                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-532           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-533                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-534                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-535           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-536                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-90                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-537                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-538           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-539                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-540                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-541           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-542                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-91                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-543                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-544           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-545                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-546                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-547           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-548                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-92                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-549                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-550           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-551                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-552                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-553           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-554                  [-1, 64, 24, 24]          --\n",
      "AvgPool2d: 1-10                        [-1, 64, 3, 3]            --\n",
      "Linear: 1-11                           [-1, 256]                 147,712\n",
      "==========================================================================================\n",
      "Total params: 4,406,088\n",
      "Trainable params: 4,406,088\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 3.93\n",
      "==========================================================================================\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 176.06\n",
      "Params size (MB): 16.81\n",
      "Estimated Total Size (MB): 192.98\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Conv2d: 1-1                            [-1, 8, 96, 96]           216\n",
       "BatchNorm2d: 1-2                       [-1, 8, 96, 96]           16\n",
       "ReLU: 1-3                              [-1, 8, 96, 96]           --\n",
       "Conv2d: 1-4                            [-1, 16, 96, 96]          1,152\n",
       "BatchNorm2d: 1-5                       [-1, 16, 96, 96]          32\n",
       "ReLU: 1-6                              [-1, 16, 96, 96]          --\n",
       "Sequential: 1-7                        [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-1                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-1                  [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-2             [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-3                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-4                  [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-5             [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-6                    [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-2                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-7                  [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-8             [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-9                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-10                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-11            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-12                   [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-3                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-13                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-14            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-15                   [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-16                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-17            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-18                   [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-4                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-19                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-20            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-21                   [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-22                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-23            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-24                   [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-5                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-25                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-26            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-27                   [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-28                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-29            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-30                   [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-6                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-31                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-32            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-33                   [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-34                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-35            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-36                   [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-7                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-37                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-38            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-39                   [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-40                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-41            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-42                   [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-8                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-43                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-44            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-45                   [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-46                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-47            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-48                   [-1, 16, 96, 96]          --\n",
       "Sequential: 1-8                        [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-9                    [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-49                 [-1, 32, 48, 48]          4,608\n",
       "|    |    BatchNorm2d: 3-50            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-51                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-52                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-53            [-1, 32, 48, 48]          64\n",
       "|    |    Sequential: 3-54             [-1, 32, 48, 48]          4,672\n",
       "|    |    ReLU: 3-55                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-10                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-56                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-57            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-58                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-59                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-60            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-61                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-11                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-62                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-63            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-64                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-65                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-66            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-67                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-12                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-68                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-69            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-70                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-71                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-72            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-73                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-13                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-74                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-75            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-76                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-77                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-78            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-79                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-14                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-80                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-81            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-82                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-83                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-84            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-85                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-15                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-86                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-87            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-88                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-89                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-90            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-91                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-16                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-92                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-93            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-94                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-95                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-96            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-97                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-17                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-98                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-99            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-100                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-101                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-102           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-103                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-18                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-104                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-105           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-106                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-107                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-108           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-109                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-19                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-110                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-111           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-112                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-113                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-114           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-115                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-20                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-116                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-117           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-118                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-119                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-120           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-121                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-21                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-122                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-123           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-124                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-125                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-126           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-127                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-22                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-128                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-129           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-130                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-131                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-132           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-133                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-23                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-134                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-135           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-136                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-137                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-138           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-139                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-24                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-140                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-141           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-142                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-143                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-144           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-145                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-25                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-146                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-147           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-148                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-149                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-150           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-151                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-26                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-152                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-153           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-154                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-155                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-156           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-157                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-27                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-158                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-159           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-160                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-161                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-162           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-163                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-28                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-164                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-165           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-166                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-167                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-168           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-169                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-29                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-170                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-171           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-172                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-173                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-174           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-175                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-30                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-176                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-177           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-178                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-179                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-180           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-181                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-31                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-182                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-183           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-184                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-185                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-186           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-187                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-32                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-188                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-189           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-190                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-191                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-192           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-193                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-33                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-194                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-195           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-196                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-197                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-198           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-199                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-34                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-200                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-201           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-202                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-203                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-204           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-205                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-35                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-206                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-207           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-208                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-209                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-210           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-211                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-36                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-212                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-213           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-214                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-215                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-216           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-217                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-37                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-218                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-219           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-220                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-221                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-222           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-223                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-38                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-224                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-225           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-226                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-227                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-228           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-229                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-39                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-230                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-231           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-232                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-233                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-234           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-235                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-40                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-236                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-237           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-238                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-239                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-240           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-241                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-41                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-242                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-243           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-244                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-245                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-246           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-247                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-42                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-248                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-249           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-250                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-251                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-252           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-253                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-43                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-254                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-255           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-256                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-257                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-258           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-259                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-44                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-260                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-261           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-262                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-263                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-264           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-265                  [-1, 32, 48, 48]          --\n",
       "Sequential: 1-9                        [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-45                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-266                [-1, 64, 24, 24]          18,432\n",
       "|    |    BatchNorm2d: 3-267           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-268                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-269                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-270           [-1, 64, 24, 24]          128\n",
       "|    |    Sequential: 3-271            [-1, 64, 24, 24]          18,560\n",
       "|    |    ReLU: 3-272                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-46                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-273                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-274           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-275                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-276                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-277           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-278                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-47                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-279                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-280           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-281                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-282                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-283           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-284                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-48                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-285                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-286           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-287                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-288                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-289           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-290                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-49                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-291                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-292           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-293                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-294                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-295           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-296                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-50                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-297                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-298           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-299                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-300                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-301           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-302                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-51                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-303                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-304           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-305                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-306                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-307           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-308                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-52                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-309                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-310           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-311                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-312                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-313           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-314                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-53                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-315                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-316           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-317                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-318                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-319           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-320                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-54                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-321                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-322           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-323                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-324                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-325           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-326                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-55                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-327                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-328           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-329                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-330                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-331           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-332                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-56                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-333                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-334           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-335                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-336                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-337           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-338                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-57                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-339                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-340           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-341                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-342                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-343           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-344                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-58                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-345                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-346           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-347                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-348                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-349           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-350                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-59                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-351                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-352           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-353                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-354                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-355           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-356                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-60                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-357                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-358           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-359                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-360                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-361           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-362                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-61                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-363                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-364           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-365                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-366                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-367           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-368                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-62                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-369                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-370           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-371                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-372                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-373           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-374                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-63                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-375                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-376           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-377                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-378                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-379           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-380                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-64                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-381                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-382           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-383                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-384                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-385           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-386                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-65                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-387                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-388           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-389                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-390                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-391           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-392                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-66                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-393                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-394           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-395                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-396                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-397           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-398                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-67                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-399                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-400           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-401                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-402                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-403           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-404                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-68                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-405                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-406           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-407                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-408                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-409           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-410                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-69                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-411                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-412           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-413                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-414                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-415           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-416                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-70                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-417                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-418           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-419                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-420                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-421           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-422                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-71                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-423                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-424           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-425                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-426                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-427           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-428                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-72                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-429                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-430           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-431                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-432                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-433           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-434                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-73                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-435                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-436           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-437                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-438                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-439           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-440                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-74                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-441                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-442           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-443                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-444                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-445           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-446                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-75                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-447                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-448           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-449                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-450                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-451           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-452                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-76                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-453                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-454           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-455                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-456                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-457           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-458                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-77                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-459                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-460           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-461                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-462                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-463           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-464                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-78                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-465                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-466           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-467                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-468                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-469           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-470                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-79                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-471                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-472           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-473                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-474                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-475           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-476                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-80                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-477                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-478           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-479                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-480                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-481           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-482                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-81                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-483                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-484           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-485                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-486                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-487           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-488                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-82                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-489                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-490           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-491                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-492                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-493           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-494                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-83                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-495                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-496           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-497                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-498                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-499           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-500                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-84                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-501                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-502           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-503                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-504                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-505           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-506                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-85                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-507                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-508           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-509                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-510                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-511           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-512                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-86                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-513                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-514           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-515                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-516                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-517           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-518                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-87                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-519                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-520           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-521                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-522                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-523           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-524                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-88                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-525                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-526           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-527                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-528                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-529           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-530                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-89                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-531                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-532           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-533                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-534                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-535           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-536                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-90                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-537                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-538           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-539                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-540                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-541           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-542                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-91                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-543                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-544           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-545                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-546                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-547           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-548                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-92                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-549                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-550           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-551                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-552                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-553           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-554                  [-1, 64, 24, 24]          --\n",
       "AvgPool2d: 1-10                        [-1, 64, 3, 3]            --\n",
       "Linear: 1-11                           [-1, 256]                 147,712\n",
       "==========================================================================================\n",
       "Total params: 4,406,088\n",
       "Trainable params: 4,406,088\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 3.93\n",
       "==========================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 176.06\n",
       "Params size (MB): 16.81\n",
       "Estimated Total Size (MB): 192.98\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "def conv_res(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual block\n",
    "class res_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(res_block, self).__init__()\n",
    "        self.conv1 = conv_res(in_channels, out_channels, stride)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv_res(out_channels, out_channels)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.bn(self.conv1(x)))\n",
    "        out = self.bn1(self.conv2(out))\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# ResNet\n",
    "class res_net(nn.Module):\n",
    "    def __init__(self, block, layers, triplet=False, num_classes=10):\n",
    "        super(res_net, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.triplet = triplet\n",
    "        self.conv = conv_res(3, 8)\n",
    "        self.conv1 = conv_res(8, 16)\n",
    "        self.bn = nn.BatchNorm2d(8)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.rep_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.rep_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.rep_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc1 = nn.Linear(576, 256)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def rep_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv_res(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward_pass(self,x):\n",
    "        out = self.relu(self.bn(self.conv(x)))\n",
    "        out = self.relu(self.bn1(self.conv1(out)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "#     def dual_pass(self, x1, x2):\n",
    "#         return self.sigmoid(self.forward_pass(x1)), self.sigmoid(self.forward_pass(x2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "       \n",
    "        if self.triplet:\n",
    "\n",
    "            return self.forward_pass(x)\n",
    "        \n",
    "        else:\n",
    "            out = self.relu(self.forward_pass(x))\n",
    "            return self.fc2(out)\n",
    "        \n",
    "    \n",
    "# resnet = res_net(res_block, [4, 16, 16*2], triplet=True, num_classes=len(classes))\n",
    "# \n",
    "resnet = res_net(res_block, [8, 36, 48], triplet=True, num_classes=len(classes))\n",
    "from torchsummary import summary\n",
    "summary(resnet,(3,96,96))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "wErXEqnGB0ZL",
    "outputId": "6fc145e8-aa18-4018-9ab3-711cc850c0e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mneuronics\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">feasible-thunder-13</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/neuronics/uncategorized\" target=\"_blank\">https://wandb.ai/neuronics/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/neuronics/uncategorized/runs/372xbyas\" target=\"_blank\">https://wandb.ai/neuronics/uncategorized/runs/372xbyas</a><br/>\n",
       "                Run data is saved locally in <code>/data/sathya/viper/wandb/run-20210725_001931-372xbyas</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name         | Type              | Params\n",
      "---------------------------------------------------\n",
      "0 | model        | res_net           | 4.4 M \n",
      "1 | accuracy     | Accuracy          | 0     \n",
      "2 | triplet_loss | TripletMarginLoss | 0     \n",
      "3 | fc2          | Linear            | 16.4 K\n",
      "4 | fc3          | Linear            | 325   \n",
      "5 | relu         | ReLU              | 0     \n",
      "---------------------------------------------------\n",
      "4.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.693    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-08.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f2ef3570244f949ea0ae8ce543cbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.4473e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.5492e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0611e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.4549e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.5451e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.9389e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.0451e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.7553e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.7553e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.0451e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.9389e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.5451e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.4549e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0611e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.5492e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.4473e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-08.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.4473e-04.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback_cn = ModelCheckpoint(\n",
    "        monitor='train_loss',\n",
    "        mode = 'min',\n",
    "        save_last=True,\n",
    "        dirpath='weights/triplet_loss',\n",
    "        filename='CE_loss-{epoch:02d}-{train_loss:.8f}'\n",
    "    )\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='valid_acc',\n",
    "        mode = 'max',\n",
    "        save_last=True,\n",
    "        dirpath='weights/triplet_loss+focal/256_CE_8,36,48-P',\n",
    "        filename='CE_loss-{epoch:02d}-{valid_acc:.3f}'\n",
    "    )\n",
    "import wandb\n",
    "wandb.init()\n",
    "\n",
    "wandb.watch(resnet)\n",
    "import ipdb\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = 1.\n",
    "        self.eps = 1e-9\n",
    "\n",
    "    def forward(self, output1, output2, target, size_average=True):\n",
    "        distances = (output2 - output1).pow(2).sum(1)  # squared distances\n",
    "        losses = 0.5 * (float(target) * distances +\n",
    "                        float(1 + -1 * target) * F.relu(self.margin - (distances + self.eps).sqrt()).pow(2))\n",
    "        return losses.mean() if size_average else losses.sum()\n",
    "    \n",
    "contrastive_loss = ContrastiveLoss()\n",
    "\n",
    "class Net(pl.LightningModule):\n",
    "    def __init__(self, model, triplet=False):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "        self.triplet = triplet\n",
    "        self.triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 5)\n",
    "        self.alpha = 1\n",
    "        self.gamma = 2\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x1, x2=None):\n",
    "        if self.triplet:\n",
    "            embedding1 = self.model(x1)\n",
    "            embedding2 = self.model(x2)\n",
    "            return embedding1, embedding2\n",
    "        \n",
    "        else:\n",
    "\n",
    "            embedding = self.model(x1)\n",
    "            return embedding\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = SWA(torch.optim.Adam(self.model.parameters(),  lr=1e-8))\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer,\n",
    "                                                                    T_max=10,\n",
    "                                                                    eta_min=1e-2,\n",
    "                                                                    verbose=True)\n",
    "\n",
    "        return {'optimizer': self.optimizer, 'lr_scheduler': self.scheduler}\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        if self.triplet:\n",
    "            (anc,lab_anc),(pos,lab_pos),(neg,lab_neg) = train_batch\n",
    "           \n",
    "            z_anc = self.model(anc)\n",
    "            z_pos = self.model(pos)\n",
    "            z_neg = self.model(neg)\n",
    "            cont_pos = contrastive_loss(z_anc, z_pos, 1)\n",
    "            cont_neg = contrastive_loss(z_anc, z_neg, 0)\n",
    "            \n",
    "            \n",
    "            z = self.fc2(self.relu(z_anc))\n",
    "            z = self.fc3(self.relu(z))\n",
    "\n",
    "           #Contrastive Loss\n",
    "\n",
    "    \n",
    "            \n",
    "            \n",
    "            CE_loss = F.cross_entropy(z,lab_anc)\n",
    "            pt = torch.exp(-CE_loss)\n",
    "            F_loss = self.alpha * (1-pt)**self.gamma * CE_loss\n",
    "            \n",
    "            loss = self.triplet_loss(z_anc, z_pos, z_neg) + F_loss# + cont_pos + cont_neg\n",
    "            acc = self.accuracy(z, lab_anc)\n",
    "            logs = {'train_loss': loss,'train_acc':acc , 'lr': self.optimizer.param_groups[0]['lr']}\n",
    "            self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "            return loss\n",
    "\n",
    "        \n",
    "        else:\n",
    "            x, y = train_batch\n",
    "            z = self.relu(self.model(x))\n",
    "            z = self.relu(self.fc2(z))\n",
    "            z = self.fc3(z)\n",
    "            loss = F.cross_entropy(z,y)\n",
    "            acc = self.accuracy(z, y)\n",
    "            logs = {'train_loss': loss, 'train_acc': acc, 'lr': self.optimizer.param_groups[0]['lr']}\n",
    "            self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "            return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "\n",
    "            x, y = val_batch\n",
    "            z = self.relu(self.model(x))\n",
    "            z = self.fc2(z)\n",
    "            z = self.fc3(self.relu(z))\n",
    "            loss = F.cross_entropy(z, y)\n",
    "            acc = self.accuracy(z, y)\n",
    "            logs = {'valid_loss': loss, 'valid_acc': acc}\n",
    "            self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "            wandb.log({\"valid_acc\": acc})\n",
    "            return loss\n",
    "  \n",
    "    def training_epoch_end(self, outs):\n",
    "        self.log('train_acc_epoch', self.accuracy.compute())\n",
    "\n",
    "# model\n",
    "model = Net(resnet, triplet=config.triplet)\n",
    "\n",
    "# training\n",
    "trainer = pl.Trainer(gpus=1,precision=16, max_epochs=600, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model, train_dataloader_triplet, val_dataloader)\n",
    "    \n",
    "    \n",
    "    # Have removed brightness augmentor run again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "res_net: 1-1                           [-1, 256]                 --\n",
      "|    Conv2d: 2-1                       [-1, 8, 96, 96]           216\n",
      "|    BatchNorm2d: 2-2                  [-1, 8, 96, 96]           16\n",
      "|    ReLU: 2-3                         [-1, 8, 96, 96]           --\n",
      "|    Conv2d: 2-4                       [-1, 16, 96, 96]          1,152\n",
      "|    BatchNorm2d: 2-5                  [-1, 16, 96, 96]          32\n",
      "|    ReLU: 2-6                         [-1, 16, 96, 96]          --\n",
      "|    Sequential: 2-7                   [-1, 16, 96, 96]          --\n",
      "|    |    res_block: 3-1               [-1, 16, 96, 96]          4,672\n",
      "|    |    res_block: 3-2               [-1, 16, 96, 96]          4,672\n",
      "|    |    res_block: 3-3               [-1, 16, 96, 96]          4,672\n",
      "|    |    res_block: 3-4               [-1, 16, 96, 96]          4,672\n",
      "|    |    res_block: 3-5               [-1, 16, 96, 96]          4,672\n",
      "|    |    res_block: 3-6               [-1, 16, 96, 96]          4,672\n",
      "|    |    res_block: 3-7               [-1, 16, 96, 96]          4,672\n",
      "|    |    res_block: 3-8               [-1, 16, 96, 96]          4,672\n",
      "|    Sequential: 2-8                   [-1, 32, 48, 48]          --\n",
      "|    |    res_block: 3-9               [-1, 32, 48, 48]          18,624\n",
      "|    |    res_block: 3-10              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-11              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-12              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-13              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-14              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-15              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-16              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-17              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-18              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-19              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-20              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-21              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-22              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-23              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-24              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-25              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-26              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-27              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-28              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-29              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-30              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-31              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-32              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-33              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-34              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-35              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-36              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-37              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-38              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-39              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-40              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-41              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-42              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-43              [-1, 32, 48, 48]          18,560\n",
      "|    |    res_block: 3-44              [-1, 32, 48, 48]          18,560\n",
      "|    Sequential: 2-9                   [-1, 64, 24, 24]          --\n",
      "|    |    res_block: 3-45              [-1, 64, 24, 24]          74,112\n",
      "|    |    res_block: 3-46              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-47              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-48              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-49              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-50              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-51              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-52              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-53              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-54              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-55              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-56              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-57              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-58              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-59              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-60              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-61              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-62              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-63              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-64              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-65              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-66              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-67              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-68              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-69              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-70              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-71              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-72              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-73              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-74              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-75              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-76              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-77              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-78              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-79              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-80              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-81              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-82              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-83              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-84              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-85              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-86              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-87              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-88              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-89              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-90              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-91              [-1, 64, 24, 24]          73,984\n",
      "|    |    res_block: 3-92              [-1, 64, 24, 24]          73,984\n",
      "|    AvgPool2d: 2-10                   [-1, 64, 3, 3]            --\n",
      "|    Linear: 2-11                      [-1, 256]                 147,712\n",
      "ReLU: 1-2                              [-1, 256]                 --\n",
      "Linear: 1-3                            [-1, 64]                  16,448\n",
      "ReLU: 1-4                              [-1, 64]                  --\n",
      "Linear: 1-5                            [-1, 5]                   325\n",
      "==========================================================================================\n",
      "Total params: 4,422,861\n",
      "Trainable params: 4,422,861\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 3.91\n",
      "==========================================================================================\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 174.38\n",
      "Params size (MB): 16.87\n",
      "Estimated Total Size (MB): 191.35\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "res_net: 1-1                           [-1, 256]                 --\n",
       "|    Conv2d: 2-1                       [-1, 8, 96, 96]           216\n",
       "|    BatchNorm2d: 2-2                  [-1, 8, 96, 96]           16\n",
       "|    ReLU: 2-3                         [-1, 8, 96, 96]           --\n",
       "|    Conv2d: 2-4                       [-1, 16, 96, 96]          1,152\n",
       "|    BatchNorm2d: 2-5                  [-1, 16, 96, 96]          32\n",
       "|    ReLU: 2-6                         [-1, 16, 96, 96]          --\n",
       "|    Sequential: 2-7                   [-1, 16, 96, 96]          --\n",
       "|    |    res_block: 3-1               [-1, 16, 96, 96]          4,672\n",
       "|    |    res_block: 3-2               [-1, 16, 96, 96]          4,672\n",
       "|    |    res_block: 3-3               [-1, 16, 96, 96]          4,672\n",
       "|    |    res_block: 3-4               [-1, 16, 96, 96]          4,672\n",
       "|    |    res_block: 3-5               [-1, 16, 96, 96]          4,672\n",
       "|    |    res_block: 3-6               [-1, 16, 96, 96]          4,672\n",
       "|    |    res_block: 3-7               [-1, 16, 96, 96]          4,672\n",
       "|    |    res_block: 3-8               [-1, 16, 96, 96]          4,672\n",
       "|    Sequential: 2-8                   [-1, 32, 48, 48]          --\n",
       "|    |    res_block: 3-9               [-1, 32, 48, 48]          18,624\n",
       "|    |    res_block: 3-10              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-11              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-12              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-13              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-14              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-15              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-16              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-17              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-18              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-19              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-20              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-21              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-22              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-23              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-24              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-25              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-26              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-27              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-28              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-29              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-30              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-31              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-32              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-33              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-34              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-35              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-36              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-37              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-38              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-39              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-40              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-41              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-42              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-43              [-1, 32, 48, 48]          18,560\n",
       "|    |    res_block: 3-44              [-1, 32, 48, 48]          18,560\n",
       "|    Sequential: 2-9                   [-1, 64, 24, 24]          --\n",
       "|    |    res_block: 3-45              [-1, 64, 24, 24]          74,112\n",
       "|    |    res_block: 3-46              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-47              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-48              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-49              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-50              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-51              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-52              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-53              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-54              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-55              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-56              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-57              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-58              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-59              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-60              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-61              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-62              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-63              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-64              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-65              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-66              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-67              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-68              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-69              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-70              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-71              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-72              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-73              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-74              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-75              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-76              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-77              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-78              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-79              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-80              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-81              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-82              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-83              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-84              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-85              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-86              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-87              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-88              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-89              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-90              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-91              [-1, 64, 24, 24]          73,984\n",
       "|    |    res_block: 3-92              [-1, 64, 24, 24]          73,984\n",
       "|    AvgPool2d: 2-10                   [-1, 64, 3, 3]            --\n",
       "|    Linear: 2-11                      [-1, 256]                 147,712\n",
       "ReLU: 1-2                              [-1, 256]                 --\n",
       "Linear: 1-3                            [-1, 64]                  16,448\n",
       "ReLU: 1-4                              [-1, 64]                  --\n",
       "Linear: 1-5                            [-1, 5]                   325\n",
       "==========================================================================================\n",
       "Total params: 4,422,861\n",
       "Trainable params: 4,422,861\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 3.91\n",
       "==========================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 174.38\n",
       "Params size (MB): 16.87\n",
       "Estimated Total Size (MB): 191.35\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Train Final Classification Layers\n",
    "\n",
    "\n",
    "\n",
    "class final_net(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(final_net, self).__init__()\n",
    "        self.model = model\n",
    "#         self.accuracy = torchmetrics.Accuracy()\n",
    "#         self.triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "#         self.fc2 = nn.Linear(576, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "#         out = self.fc2(out)              #Without ReLU\n",
    "#         out = self.fc2(nn.ReLU(out))\n",
    "        out = self.fc2(self.relu(out))\n",
    "        out = self.fc3(self.relu(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "    \n",
    "FN = final_net(resnet)\n",
    "chkpoint = torch.load('./weights/triplet_loss+focal/256_CE_8,36,48/CE_loss-epoch=193-valid_acc=0.781.ckpt')['state_dict']\n",
    "\n",
    "FN.load_state_dict(chkpoint)\n",
    "\n",
    "# from torchsummary import summary\n",
    "summary(FN,(3,96,96))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for batch_idx, data in tqdm(enumerate(test_dataloader)):\n",
    "    img_path, img, _ = data\n",
    "    model_out = \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in FN.named_parameters():\n",
    "#     if \"fc2\" not in name:\n",
    "# #         print(name)\n",
    "#         param.requires_grad = False\n",
    "# #     params.append(param.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class Net(pl.LightningModule):\n",
    "#     def __init__(self, model, triplet=False):\n",
    "#         super().__init__()\n",
    "#         self.model = model\n",
    "#         self.accuracy = torchmetrics.Accuracy()\n",
    "#         self.triplet = triplet\n",
    "#         self.triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "#         self.fc2 = nn.Linear(64, 5)\n",
    "#         self.alpha = 1\n",
    "#         self.gamma = 2\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x1, x2=None):\n",
    "      \n",
    "#         embedding = self.model(x1)\n",
    "#         return embedding\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         self.optimizer = SWA(torch.optim.Adam(self.model.parameters(),  lr=1e-8))\n",
    "#         self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer,\n",
    "#                                                                     T_max=10,\n",
    "#                                                                     eta_min=1e-2,\n",
    "#                                                                     verbose=True)\n",
    "\n",
    "#         return {'optimizer': self.optimizer, 'lr_scheduler': self.scheduler}\n",
    "\n",
    "#     def training_step(self, train_batch, batch_idx):\n",
    "#             x, y = train_batch\n",
    "#             z = self.model(x)\n",
    "#             loss = F.cross_entropy(z,y)\n",
    "#             acc = self.accuracy(z, y)\n",
    "#             logs = {'train_loss': loss, 'train_acc': acc, 'lr': self.optimizer.param_groups[0]['lr']}\n",
    "#             self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "#             return loss\n",
    "\n",
    "#     def validation_step(self, val_batch, batch_idx):\n",
    "\n",
    "#             x, y = val_batch\n",
    "#             z = self.model(x)\n",
    "# #             z = self.fc2(z)\n",
    "#             loss = F.cross_entropy(z, y)\n",
    "#             acc = self.accuracy(z, y)\n",
    "#             logs = {'valid_loss': loss, 'valid_acc': acc}\n",
    "#             self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "#             return loss\n",
    "  \n",
    "#     def training_epoch_end(self, outs):\n",
    "#         self.log('train_acc_epoch', self.accuracy.compute())\n",
    "\n",
    "# # model\n",
    "# model = Net(FN, triplet=False)\n",
    "\n",
    "# # training\n",
    "# trainer = pl.Trainer(gVanilla-Copy1pus=1,precision=16, max_epochs=400, callbacks=[checkpoint_callback])\n",
    "# trainer.fit(model, train_dataloader, val_dataloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import nn\n",
    "# from torch.nn import functional as F\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch.utils.data import random_split\n",
    "# from torchvision.datasets import MNIST\n",
    "# from torchvision import transforms\n",
    "# import pytorch_lightning as pl\n",
    "# import torchmetrics\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "# def conv_res(in_channels, out_channels, stride=1):\n",
    "#     return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "#                      stride=stride, padding=1, bias=False)\n",
    "\n",
    "# # Residual block\n",
    "# class res_block(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "#         super(res_block, self).__init__()\n",
    "#         self.conv1 = conv_res(in_channels, out_channels, stride)\n",
    "#         self.bn = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.conv2 = conv_res(out_channels, out_channels)\n",
    "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "#         self.downsample = downsample\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         residual = x\n",
    "#         out = self.relu(self.bn(self.conv1(x)))\n",
    "#         out = self.bn1(self.conv2(out))\n",
    "#         if self.downsample:\n",
    "#             residual = self.downsample(x)\n",
    "#         out += residual\n",
    "#         out = self.relu(out)\n",
    "#         return out\n",
    "\n",
    "# # ResNet\n",
    "# class res_net(nn.Module):\n",
    "#     def __init__(self, block, layers, triplet=False, num_classes=10):\n",
    "#         super(res_net, self).__init__()\n",
    "#         self.in_channels = 16\n",
    "#         self.triplet = triplet\n",
    "#         self.conv = conv_res(3, 8)\n",
    "#         self.conv1 = conv_res(8, 16)\n",
    "#         self.bn = nn.BatchNorm2d(8)\n",
    "#         self.bn1 = nn.BatchNorm2d(16)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.layer1 = self.rep_layer(block, 16, layers[0])\n",
    "#         self.layer2 = self.rep_layer(block, 32, layers[1], 2)\n",
    "#         self.layer3 = self.rep_layer(block, 64, layers[2], 2)\n",
    "#         self.avg_pool = nn.AvgPool2d(8)\n",
    "#         self.fc1 = nn.Linear(576, 64)\n",
    "#         self.fc2 = nn.Linear(64, num_classes)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "#     def rep_layer(self, block, out_channels, blocks, stride=1):\n",
    "#         downsample = None\n",
    "#         if (stride != 1) or (self.in_channels != out_channels):\n",
    "#             downsample = nn.Sequential(\n",
    "#                 conv_res(self.in_channels, out_channels, stride=stride),\n",
    "#                 nn.BatchNorm2d(out_channels))\n",
    "#         layers = []\n",
    "#         layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "#         self.in_channels = out_channels\n",
    "#         for i in range(1, blocks):\n",
    "#             layers.append(block(out_channels, out_channels))\n",
    "#         return nn.Sequential(*layers)\n",
    "    \n",
    "#     def forward_pass(self,x):\n",
    "#         out = self.relu(self.bn(self.conv(x)))\n",
    "#         out = self.relu(self.bn1(self.conv1(out)))\n",
    "#         out = self.layer1(out)\n",
    "#         out = self.layer2(out)\n",
    "#         out = self.layer3(out)\n",
    "#         out = self.avg_pool(out)\n",
    "#         out = out.view(out.size(0), -1)\n",
    "#         out = self.fc1(out)\n",
    "        \n",
    "#         return out\n",
    "    \n",
    "# #     def dual_pass(self, x1, x2):\n",
    "# #         return self.sigmoid(self.forward_pass(x1)), self.sigmoid(self.forward_pass(x2))\n",
    "        \n",
    "#     def forward(self, x):\n",
    "       \n",
    "#         if self.triplet:\n",
    "\n",
    "#             return self.forward_pass(x)\n",
    "        \n",
    "#         else:\n",
    "#             out = self.relu(self.forward_pass(x))\n",
    "#             return self.fc2(out)\n",
    "        \n",
    "    \n",
    "# resnet = res_net(res_block, [4, 16, 16*2], triplet=True, num_classes=5)\n",
    "\n",
    "\n",
    "\n",
    "# class final_net(nn.Module):\n",
    "#     def __init__(self, model):\n",
    "#         super(final_net, self).__init__()\n",
    "#         self.model = model\n",
    "#         self.accuracy = torchmetrics.Accuracy()\n",
    "#         self.triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "#         self.fc2 = nn.Linear(64, 5)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out = self.model(x)\n",
    "#         out = self.fc2(out)              #Without ReLU\n",
    "# #         out = self.fc2(nn.ReLU(out))\n",
    "#         return out\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# FN = final_net(resnet).to(device)\n",
    "# FN.load_state_dict(torch.load('./weights/triplet_loss+focal/vanilla/CE_loss-epoch=151-valid_acc=0.738.ckpt')['state_dict'])\n",
    "\n",
    "# from torchsummary import summary\n",
    "# summary(FN,(3,96,96))\n",
    "\n",
    "# model  = FN.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# targets, preds = [], []\n",
    "\n",
    "# train_transform = A.Compose(\n",
    "#     [\n",
    "# #        A.ShiftScaleRotate(rotate_limit=(-360, 360), shift_limit=(0.1, 0.12), scale_limit=(0.1, 0.12)),\n",
    "# #        A.HorizontalFlip(p=0.6),\n",
    "# #        A.Rotate (limit=120),\n",
    "# #        A.Perspective(scale=(0.05, 0.1)),\n",
    "# #        A.Affine (scale=1,translate_percent=0.1,rotate=40,cval=0.90,fit_output=True),\n",
    "#        ToTensorV2(),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# valid_transform = A.Compose(\n",
    "#     [\n",
    "#        ToTensorV2(),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# val_dataset = vdataset(val_df, transform = valid_transform)\n",
    "\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=8*4,\n",
    "#                         shuffle=False, num_workers=32)\n",
    "\n",
    "# for batch_idx, data in tqdm(enumerate(val_dataloader)):\n",
    "#     x, y = data\n",
    "#     targets.append(y)\n",
    "#     predictions = model(x.to(device))\n",
    "#     preds.append(torch.argmax(predictions,axis=1).cpu().detach().numpy())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.asarray(torch.argmax(predictions,axis=1).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets = np.asarray(targets)\n",
    "# preds = np.asarray(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Robet Bosch Viper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
