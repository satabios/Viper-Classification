{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mqhvo9EvN4zZ",
    "outputId": "f3cf11a3-2e55-4bd4-83dc-f16e514ec888"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "Kjhx8hHdN6CT",
    "outputId": "6fe246c9-4d3c-42e8-e559-450b99a875c0"
   },
   "outputs": [],
   "source": [
    "# %cd /content/drive/MyDrive/Robert_Bosch/dataset/Test_data/\n",
    "# %ls \n",
    "# # %mkdir -p dataset\n",
    "# !pip install ipdb\n",
    "# # !unzip Test_data.zip -d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CE_loss-epoch=193-valid_acc=0.781.ckpt'\r\n",
      "'eff-ns-b7_focal[Training].ipynb'\r\n",
      " \u001b[0m\u001b[01;34mlightning_logs\u001b[0m/\r\n",
      "'Model Infer.ipynb'\r\n",
      " Robet_Bosch_Viper-Eff-Copy1.ipynb\r\n",
      " Robet_Bosch_Viper-Eff.ipynb\r\n",
      "'Robet_Bosch_Viper- Final-256_CE.ipynb'\r\n",
      "'Robet_Bosch_Viper- Final-256CE.ipynb'\r\n",
      "'Robet_Bosch_Viper- Final-256_CE-without brightness.ipynb'\r\n",
      "'Robet_Bosch_Viper- Final-Copy2.ipynb'\r\n",
      "'Robet_Bosch_Viper- Final.ipynb'\r\n",
      "'Robet_Bosch_Viper- Transforms with dropout.ipynb'\r\n",
      " Robet_Bosch_Viper-Triplet.ipynb\r\n",
      "'Robet_Bosch_Viper- Vanilla.ipynb'\r\n",
      " Sample_Submission.csv\r\n",
      " \u001b[01;34mTest\u001b[0m/\r\n",
      " \u001b[01;34mTrain\u001b[0m/\r\n",
      " \u001b[01;34mVal\u001b[0m/\r\n",
      " \u001b[01;34mwandb\u001b[0m/\r\n",
      " \u001b[01;34mweights\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJJIIJrvOxgn",
    "outputId": "f81e88c2-2258-4f6a-d0c0-4a23c5bb41b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Points:\n",
      "Train: 970 Test: 2910\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import ipdb \n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('./')\n",
    "train_test_val = 0\n",
    "dataset = []\n",
    "k_fold = True\n",
    "folders_to_look = ['Train/','Val/'] if k_fold==True else ['Train/']\n",
    "classes = [cl.split('/')[1] for cl in glob.glob('Train/'+'/*')] #Class names\n",
    "cls_len = len(glob.glob('Train/'+'/*')) #Number of Classes in the dataset\n",
    "\n",
    "for folder in glob.iglob('*/'):\n",
    "    if(train_test_val == 0):\n",
    "        if(folder in folders_to_look):\n",
    "            for classess in glob.glob(folder+'/*'):\n",
    "                for files in glob.iglob(classess+\"/*.jpg\"):\n",
    "                    img_path = files\n",
    "                    class_id = classes.index(files.split('/')[1])\n",
    "                    dataset.append((img_path,class_id))\n",
    "\n",
    "df = pd.DataFrame(dataset,columns=['image_path','class'])\n",
    "# dataset = np.asarray(dataset)\n",
    "train_df, val_df = df.iloc[:970],df.iloc[970:]\n",
    "print(\"Data Points:\")\n",
    "print(\"Train:\",len(train_df),\"Test:\",len(val_df))\n",
    "\n",
    "\n",
    "#Checking for Class Imbalance\n",
    "cls, counts = np.unique(train_df['class'].values, return_counts=True)\n",
    "# print([print(\"class:\",classes[cls[i]],\"counts:\",counts[i]) for i in range(cls_len)])\n",
    "# Hence no class imbalance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    triplet = True\n",
    "    num_classes = len(classes)\n",
    "    clases = classes\n",
    "    train_batch_size = 8*4 # Reduce if triplet is True, defualt : 8*4*4\n",
    "    val_batch_size = 8*4*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XaqO3MNyaFy",
    "outputId": "3c755ae2-7333-4ae9-b999-d845d7e4a267"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sathya/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "#k-Fold Validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=6)\n",
    "skf.get_n_splits(len(df))\n",
    "fold = 0\n",
    "df['fold'] =0 \n",
    "for train_index, test_index in skf.split(df['image_path'],df['class']):\n",
    "    df['fold'].loc[test_index]=fold\n",
    "    fold+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['human', 'animal', 'truck', 'car', 'airplane']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wzLAAA_Kxjxw"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchcontrib.optim import SWA\n",
    "from pytorch_lightning.metrics import Metric\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "\n",
    "class vdataset(Dataset):\n",
    "    def __init__(self, df, triplet=False, transform=None):\n",
    "        self.df = df\n",
    "        self.transforms = transform\n",
    "        self.triplet = triplet\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def read_image(self, image_path):\n",
    "        image = cv2.imread(image_path).astype(np.float32)\n",
    "        image = (image-np.min(image))/(np.max(image)-np.min(image))\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)\n",
    "            image = image['image']\n",
    "        else:\n",
    "            image = np.moveaxis(image,-1,0)\n",
    "        return image\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.df.iloc[idx]\n",
    "        anchor_image_path, anchor_label = data['image_path'], data['class']\n",
    "        anchor_image = self.read_image(anchor_image_path)\n",
    "        \n",
    "        if self.triplet:                  #For Siamese Triplet Learning\n",
    "            if(anchor_label ==1 or anchor_label ==2 or anchor_label ==3):\n",
    "                if(anchor_label ==1):\n",
    "                    p=[0.4,0,0.2,0.2,0.2]\n",
    "                elif(anchor_label ==2):\n",
    "                    p=[0.2,0.2,0,0.4,0.2]\n",
    "                elif(anchor_label ==3):\n",
    "                    p=[0.2,0.2,0.4,0,0.2]\n",
    "\n",
    "                anchor_label_neg =np.random.choice(range(5),size=1,p=p)\n",
    "                negative_index = np.random.choice(train_df[train_df['class']==anchor_label_neg[0]].index)\n",
    "                negative_image_path, negative_label = train_df.iloc[negative_index]\n",
    "                negative_image = self.read_image(negative_image_path)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                \n",
    "                negative_index = np.random.choice(train_df[train_df['class']!=anchor_label].index)\n",
    "                negative_image_path, negative_label = train_df.iloc[negative_index]\n",
    "                negative_image = self.read_image(negative_image_path)\n",
    "\n",
    "\n",
    "            positive_index = np.random.choice(train_df[train_df['class']==anchor_label].index)\n",
    "            positive_image_path, positive_label = train_df.iloc[positive_index]\n",
    "            positive_image = self.read_image(positive_image_path)\n",
    "\n",
    "            return (anchor_image,anchor_label), (positive_image, positive_label),(negative_image, negative_label)\n",
    "        \n",
    "        else:\n",
    "            return anchor_image,torch.tensor(anchor_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "SUvaycUw5nZ0",
    "outputId": "5a4c2578-8330-4e8e-e834-af103a5e96d7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "#        A.ShiftScaleRotate(rotate_limit=(-360, 360), shift_limit=(0.1, 0.12), scale_limit=(0.1, 0.12)),\n",
    "       A.HorizontalFlip(p=0.5),\n",
    "       A.Sharpen(alpha=(0.3,0.5), lightness=(0.5, 1.0), always_apply= False, p=0.6) ,\n",
    "       A.Rotate (limit=180),\n",
    "#       A.RandomBrightnessContrast(brightness_limit=0.3,contrast_limit=0.2,p=0.5),\n",
    "#         iaa.Sequential([\n",
    "#         iaa.Canny(alpha=(0.0, 0.6))\n",
    "#              ]).augment_image,\n",
    "#       A.Affine (scale=None, translate_percent=None, translate_px=None, rotate=None, shear=(0,15),\n",
    "#                 interpolation=1, cval=0, cval_mask=0, mode=0, fit_output=False, always_apply=False, p=0.5),\n",
    "#        A.RandomBrightnessContrast(contrast_limit=0.2, always_apply=False, p=0.5),\n",
    "#        A.Perspective(scale=(0.05, 0.1)),\n",
    "#        A.Affine (scale=1,translate_percent=0.1,fit_output=True),\n",
    "       ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "valid_transform = A.Compose(\n",
    "    [\n",
    "       ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_dataset = vdataset(val_df, transform = valid_transform)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8*4*4,\n",
    "                        shuffle=False, num_workers=32)\n",
    "\n",
    "if (config.triplet==True):\n",
    "    #Triplet Visualization\n",
    "\n",
    "    train_dataset_triplet = vdataset(train_df,triplet=True, transform = train_transform)\n",
    "\n",
    "\n",
    "    train_dataloader_triplet = DataLoader(train_dataset_triplet, batch_size=8,\n",
    "                            shuffle=True, num_workers=32)\n",
    "    \n",
    "    \n",
    "    fig, axs = plt.subplots(5, 3)\n",
    "    fig.tight_layout()\n",
    "    cls_ind = 0\n",
    "    for i in range(5):\n",
    "\n",
    "        (anc,cls),(pos,cls),(neg,neg_cls) = train_dataset_triplet.__getitem__(197*i+1)\n",
    "        axs[i][0].imshow(anc[0,:],cmap='gray',aspect='auto')\n",
    "        axs[i][0].set_title(classes[cls])\n",
    "        axs[i][1].imshow(pos[0,:],cmap='gray', aspect='auto')\n",
    "        axs[i][1].set_title(classes[cls])\n",
    "        axs[i][2].imshow(neg[0,:],cmap='gray', aspect='auto')\n",
    "        axs[i][2].set_title(classes[neg_cls])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    train_dataset = vdataset(train_df, transform = train_transform)\n",
    "\n",
    "\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=8*4*4,\n",
    "                        shuffle=True, num_workers=32)\n",
    "    fig, axs = plt.subplots(2,3)\n",
    "    fig.tight_layout()\n",
    "    cls_ind = 0\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            test_sample,cls = train_dataset.__getitem__(190*cls_ind)\n",
    "            axs[i][j].imshow(test_sample[0,:],cmap='gray', aspect='auto')\n",
    "            axs[i][j].set_title(classes[cls])\n",
    "            cls_ind+=1\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lCL6eEUxvdBv",
    "outputId": "e5425e52-188e-4904-89d4-0dc56734b66d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Conv2d: 1-1                            [-1, 8, 96, 96]           216\n",
      "BatchNorm2d: 1-2                       [-1, 8, 96, 96]           16\n",
      "ReLU: 1-3                              [-1, 8, 96, 96]           --\n",
      "Conv2d: 1-4                            [-1, 16, 96, 96]          1,152\n",
      "BatchNorm2d: 1-5                       [-1, 16, 96, 96]          32\n",
      "ReLU: 1-6                              [-1, 16, 96, 96]          --\n",
      "Sequential: 1-7                        [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-1                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-1                  [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-2             [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-3                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-4                  [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-5             [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-6                    [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-2                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-7                  [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-8             [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-9                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-10                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-11            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-12                   [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-3                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-13                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-14            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-15                   [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-16                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-17            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-18                   [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-4                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-19                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-20            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-21                   [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-22                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-23            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-24                   [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-5                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-25                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-26            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-27                   [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-28                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-29            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-30                   [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-6                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-31                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-32            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-33                   [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-34                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-35            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-36                   [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-7                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-37                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-38            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-39                   [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-40                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-41            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-42                   [-1, 16, 96, 96]          --\n",
      "|    res_block: 2-8                    [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-43                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-44            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-45                   [-1, 16, 96, 96]          --\n",
      "|    |    Conv2d: 3-46                 [-1, 16, 96, 96]          2,304\n",
      "|    |    BatchNorm2d: 3-47            [-1, 16, 96, 96]          32\n",
      "|    |    ReLU: 3-48                   [-1, 16, 96, 96]          --\n",
      "Sequential: 1-8                        [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-9                    [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-49                 [-1, 32, 48, 48]          4,608\n",
      "|    |    BatchNorm2d: 3-50            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-51                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-52                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-53            [-1, 32, 48, 48]          64\n",
      "|    |    Sequential: 3-54             [-1, 32, 48, 48]          4,672\n",
      "|    |    ReLU: 3-55                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-10                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-56                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-57            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-58                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-59                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-60            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-61                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-11                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-62                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-63            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-64                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-65                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-66            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-67                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-12                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-68                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-69            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-70                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-71                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-72            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-73                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-13                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-74                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-75            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-76                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-77                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-78            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-79                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-14                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-80                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-81            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-82                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-83                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-84            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-85                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-15                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-86                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-87            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-88                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-89                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-90            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-91                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-16                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-92                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-93            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-94                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-95                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-96            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-97                   [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-17                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-98                 [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-99            [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-100                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-101                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-102           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-103                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-18                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-104                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-105           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-106                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-107                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-108           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-109                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-19                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-110                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-111           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-112                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-113                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-114           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-115                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-20                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-116                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-117           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-118                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-119                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-120           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-121                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-21                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-122                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-123           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-124                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-125                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-126           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-127                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-22                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-128                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-129           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-130                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-131                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-132           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-133                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-23                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-134                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-135           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-136                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-137                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-138           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-139                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-24                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-140                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-141           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-142                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-143                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-144           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-145                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-25                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-146                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-147           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-148                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-149                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-150           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-151                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-26                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-152                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-153           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-154                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-155                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-156           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-157                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-27                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-158                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-159           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-160                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-161                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-162           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-163                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-28                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-164                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-165           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-166                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-167                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-168           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-169                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-29                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-170                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-171           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-172                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-173                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-174           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-175                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-30                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-176                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-177           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-178                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-179                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-180           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-181                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-31                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-182                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-183           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-184                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-185                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-186           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-187                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-32                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-188                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-189           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-190                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-191                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-192           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-193                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-33                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-194                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-195           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-196                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-197                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-198           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-199                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-34                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-200                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-201           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-202                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-203                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-204           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-205                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-35                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-206                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-207           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-208                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-209                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-210           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-211                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-36                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-212                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-213           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-214                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-215                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-216           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-217                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-37                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-218                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-219           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-220                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-221                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-222           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-223                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-38                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-224                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-225           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-226                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-227                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-228           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-229                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-39                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-230                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-231           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-232                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-233                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-234           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-235                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-40                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-236                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-237           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-238                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-239                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-240           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-241                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-41                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-242                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-243           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-244                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-245                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-246           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-247                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-42                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-248                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-249           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-250                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-251                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-252           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-253                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-43                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-254                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-255           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-256                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-257                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-258           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-259                  [-1, 32, 48, 48]          --\n",
      "|    res_block: 2-44                   [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-260                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-261           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-262                  [-1, 32, 48, 48]          --\n",
      "|    |    Conv2d: 3-263                [-1, 32, 48, 48]          9,216\n",
      "|    |    BatchNorm2d: 3-264           [-1, 32, 48, 48]          64\n",
      "|    |    ReLU: 3-265                  [-1, 32, 48, 48]          --\n",
      "Sequential: 1-9                        [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-45                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-266                [-1, 64, 24, 24]          18,432\n",
      "|    |    BatchNorm2d: 3-267           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-268                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-269                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-270           [-1, 64, 24, 24]          128\n",
      "|    |    Sequential: 3-271            [-1, 64, 24, 24]          18,560\n",
      "|    |    ReLU: 3-272                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-46                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-273                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-274           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-275                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-276                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-277           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-278                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-47                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-279                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-280           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-281                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-282                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-283           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-284                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-48                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-285                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-286           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-287                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-288                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-289           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-290                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-49                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-291                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-292           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-293                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-294                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-295           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-296                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-50                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-297                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-298           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-299                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-300                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-301           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-302                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-51                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-303                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-304           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-305                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-306                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-307           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-308                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-52                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-309                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-310           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-311                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-312                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-313           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-314                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-53                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-315                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-316           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-317                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-318                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-319           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-320                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-54                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-321                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-322           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-323                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-324                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-325           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-326                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-55                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-327                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-328           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-329                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-330                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-331           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-332                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-56                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-333                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-334           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-335                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-336                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-337           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-338                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-57                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-339                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-340           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-341                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-342                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-343           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-344                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-58                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-345                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-346           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-347                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-348                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-349           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-350                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-59                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-351                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-352           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-353                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-354                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-355           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-356                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-60                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-357                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-358           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-359                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-360                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-361           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-362                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-61                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-363                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-364           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-365                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-366                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-367           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-368                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-62                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-369                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-370           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-371                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-372                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-373           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-374                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-63                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-375                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-376           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-377                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-378                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-379           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-380                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-64                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-381                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-382           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-383                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-384                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-385           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-386                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-65                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-387                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-388           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-389                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-390                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-391           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-392                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-66                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-393                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-394           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-395                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-396                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-397           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-398                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-67                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-399                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-400           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-401                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-402                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-403           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-404                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-68                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-405                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-406           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-407                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-408                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-409           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-410                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-69                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-411                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-412           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-413                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-414                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-415           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-416                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-70                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-417                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-418           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-419                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-420                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-421           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-422                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-71                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-423                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-424           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-425                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-426                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-427           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-428                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-72                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-429                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-430           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-431                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-432                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-433           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-434                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-73                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-435                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-436           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-437                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-438                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-439           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-440                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-74                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-441                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-442           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-443                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-444                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-445           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-446                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-75                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-447                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-448           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-449                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-450                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-451           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-452                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-76                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-453                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-454           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-455                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-456                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-457           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-458                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-77                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-459                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-460           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-461                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-462                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-463           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-464                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-78                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-465                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-466           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-467                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-468                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-469           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-470                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-79                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-471                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-472           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-473                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-474                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-475           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-476                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-80                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-477                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-478           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-479                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-480                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-481           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-482                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-81                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-483                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-484           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-485                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-486                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-487           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-488                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-82                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-489                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-490           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-491                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-492                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-493           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-494                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-83                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-495                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-496           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-497                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-498                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-499           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-500                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-84                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-501                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-502           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-503                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-504                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-505           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-506                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-85                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-507                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-508           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-509                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-510                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-511           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-512                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-86                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-513                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-514           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-515                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-516                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-517           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-518                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-87                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-519                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-520           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-521                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-522                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-523           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-524                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-88                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-525                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-526           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-527                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-528                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-529           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-530                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-89                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-531                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-532           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-533                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-534                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-535           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-536                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-90                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-537                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-538           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-539                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-540                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-541           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-542                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-91                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-543                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-544           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-545                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-546                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-547           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-548                  [-1, 64, 24, 24]          --\n",
      "|    res_block: 2-92                   [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-549                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-550           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-551                  [-1, 64, 24, 24]          --\n",
      "|    |    Conv2d: 3-552                [-1, 64, 24, 24]          36,864\n",
      "|    |    BatchNorm2d: 3-553           [-1, 64, 24, 24]          128\n",
      "|    |    ReLU: 3-554                  [-1, 64, 24, 24]          --\n",
      "AvgPool2d: 1-10                        [-1, 64, 3, 3]            --\n",
      "Linear: 1-11                           [-1, 256]                 147,712\n",
      "==========================================================================================\n",
      "Total params: 4,406,088\n",
      "Trainable params: 4,406,088\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 3.93\n",
      "==========================================================================================\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 176.06\n",
      "Params size (MB): 16.81\n",
      "Estimated Total Size (MB): 192.98\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Conv2d: 1-1                            [-1, 8, 96, 96]           216\n",
       "BatchNorm2d: 1-2                       [-1, 8, 96, 96]           16\n",
       "ReLU: 1-3                              [-1, 8, 96, 96]           --\n",
       "Conv2d: 1-4                            [-1, 16, 96, 96]          1,152\n",
       "BatchNorm2d: 1-5                       [-1, 16, 96, 96]          32\n",
       "ReLU: 1-6                              [-1, 16, 96, 96]          --\n",
       "Sequential: 1-7                        [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-1                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-1                  [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-2             [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-3                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-4                  [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-5             [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-6                    [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-2                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-7                  [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-8             [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-9                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-10                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-11            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-12                   [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-3                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-13                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-14            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-15                   [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-16                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-17            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-18                   [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-4                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-19                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-20            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-21                   [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-22                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-23            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-24                   [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-5                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-25                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-26            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-27                   [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-28                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-29            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-30                   [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-6                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-31                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-32            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-33                   [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-34                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-35            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-36                   [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-7                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-37                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-38            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-39                   [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-40                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-41            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-42                   [-1, 16, 96, 96]          --\n",
       "|    res_block: 2-8                    [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-43                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-44            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-45                   [-1, 16, 96, 96]          --\n",
       "|    |    Conv2d: 3-46                 [-1, 16, 96, 96]          2,304\n",
       "|    |    BatchNorm2d: 3-47            [-1, 16, 96, 96]          32\n",
       "|    |    ReLU: 3-48                   [-1, 16, 96, 96]          --\n",
       "Sequential: 1-8                        [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-9                    [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-49                 [-1, 32, 48, 48]          4,608\n",
       "|    |    BatchNorm2d: 3-50            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-51                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-52                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-53            [-1, 32, 48, 48]          64\n",
       "|    |    Sequential: 3-54             [-1, 32, 48, 48]          4,672\n",
       "|    |    ReLU: 3-55                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-10                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-56                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-57            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-58                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-59                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-60            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-61                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-11                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-62                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-63            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-64                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-65                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-66            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-67                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-12                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-68                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-69            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-70                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-71                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-72            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-73                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-13                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-74                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-75            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-76                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-77                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-78            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-79                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-14                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-80                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-81            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-82                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-83                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-84            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-85                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-15                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-86                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-87            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-88                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-89                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-90            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-91                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-16                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-92                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-93            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-94                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-95                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-96            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-97                   [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-17                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-98                 [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-99            [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-100                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-101                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-102           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-103                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-18                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-104                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-105           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-106                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-107                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-108           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-109                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-19                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-110                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-111           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-112                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-113                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-114           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-115                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-20                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-116                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-117           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-118                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-119                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-120           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-121                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-21                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-122                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-123           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-124                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-125                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-126           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-127                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-22                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-128                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-129           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-130                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-131                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-132           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-133                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-23                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-134                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-135           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-136                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-137                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-138           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-139                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-24                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-140                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-141           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-142                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-143                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-144           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-145                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-25                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-146                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-147           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-148                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-149                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-150           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-151                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-26                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-152                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-153           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-154                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-155                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-156           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-157                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-27                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-158                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-159           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-160                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-161                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-162           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-163                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-28                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-164                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-165           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-166                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-167                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-168           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-169                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-29                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-170                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-171           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-172                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-173                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-174           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-175                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-30                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-176                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-177           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-178                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-179                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-180           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-181                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-31                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-182                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-183           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-184                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-185                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-186           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-187                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-32                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-188                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-189           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-190                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-191                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-192           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-193                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-33                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-194                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-195           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-196                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-197                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-198           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-199                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-34                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-200                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-201           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-202                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-203                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-204           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-205                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-35                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-206                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-207           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-208                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-209                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-210           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-211                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-36                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-212                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-213           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-214                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-215                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-216           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-217                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-37                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-218                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-219           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-220                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-221                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-222           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-223                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-38                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-224                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-225           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-226                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-227                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-228           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-229                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-39                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-230                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-231           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-232                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-233                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-234           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-235                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-40                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-236                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-237           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-238                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-239                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-240           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-241                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-41                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-242                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-243           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-244                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-245                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-246           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-247                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-42                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-248                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-249           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-250                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-251                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-252           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-253                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-43                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-254                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-255           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-256                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-257                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-258           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-259                  [-1, 32, 48, 48]          --\n",
       "|    res_block: 2-44                   [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-260                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-261           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-262                  [-1, 32, 48, 48]          --\n",
       "|    |    Conv2d: 3-263                [-1, 32, 48, 48]          9,216\n",
       "|    |    BatchNorm2d: 3-264           [-1, 32, 48, 48]          64\n",
       "|    |    ReLU: 3-265                  [-1, 32, 48, 48]          --\n",
       "Sequential: 1-9                        [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-45                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-266                [-1, 64, 24, 24]          18,432\n",
       "|    |    BatchNorm2d: 3-267           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-268                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-269                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-270           [-1, 64, 24, 24]          128\n",
       "|    |    Sequential: 3-271            [-1, 64, 24, 24]          18,560\n",
       "|    |    ReLU: 3-272                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-46                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-273                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-274           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-275                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-276                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-277           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-278                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-47                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-279                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-280           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-281                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-282                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-283           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-284                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-48                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-285                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-286           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-287                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-288                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-289           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-290                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-49                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-291                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-292           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-293                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-294                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-295           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-296                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-50                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-297                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-298           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-299                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-300                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-301           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-302                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-51                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-303                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-304           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-305                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-306                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-307           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-308                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-52                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-309                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-310           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-311                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-312                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-313           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-314                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-53                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-315                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-316           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-317                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-318                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-319           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-320                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-54                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-321                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-322           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-323                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-324                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-325           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-326                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-55                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-327                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-328           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-329                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-330                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-331           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-332                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-56                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-333                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-334           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-335                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-336                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-337           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-338                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-57                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-339                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-340           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-341                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-342                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-343           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-344                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-58                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-345                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-346           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-347                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-348                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-349           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-350                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-59                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-351                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-352           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-353                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-354                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-355           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-356                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-60                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-357                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-358           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-359                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-360                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-361           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-362                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-61                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-363                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-364           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-365                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-366                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-367           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-368                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-62                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-369                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-370           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-371                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-372                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-373           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-374                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-63                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-375                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-376           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-377                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-378                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-379           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-380                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-64                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-381                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-382           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-383                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-384                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-385           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-386                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-65                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-387                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-388           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-389                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-390                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-391           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-392                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-66                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-393                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-394           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-395                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-396                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-397           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-398                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-67                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-399                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-400           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-401                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-402                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-403           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-404                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-68                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-405                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-406           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-407                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-408                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-409           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-410                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-69                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-411                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-412           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-413                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-414                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-415           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-416                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-70                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-417                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-418           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-419                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-420                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-421           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-422                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-71                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-423                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-424           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-425                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-426                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-427           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-428                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-72                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-429                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-430           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-431                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-432                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-433           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-434                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-73                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-435                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-436           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-437                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-438                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-439           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-440                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-74                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-441                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-442           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-443                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-444                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-445           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-446                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-75                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-447                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-448           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-449                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-450                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-451           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-452                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-76                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-453                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-454           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-455                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-456                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-457           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-458                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-77                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-459                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-460           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-461                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-462                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-463           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-464                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-78                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-465                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-466           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-467                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-468                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-469           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-470                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-79                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-471                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-472           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-473                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-474                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-475           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-476                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-80                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-477                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-478           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-479                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-480                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-481           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-482                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-81                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-483                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-484           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-485                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-486                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-487           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-488                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-82                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-489                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-490           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-491                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-492                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-493           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-494                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-83                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-495                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-496           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-497                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-498                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-499           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-500                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-84                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-501                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-502           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-503                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-504                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-505           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-506                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-85                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-507                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-508           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-509                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-510                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-511           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-512                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-86                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-513                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-514           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-515                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-516                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-517           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-518                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-87                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-519                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-520           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-521                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-522                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-523           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-524                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-88                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-525                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-526           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-527                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-528                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-529           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-530                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-89                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-531                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-532           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-533                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-534                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-535           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-536                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-90                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-537                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-538           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-539                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-540                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-541           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-542                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-91                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-543                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-544           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-545                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-546                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-547           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-548                  [-1, 64, 24, 24]          --\n",
       "|    res_block: 2-92                   [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-549                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-550           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-551                  [-1, 64, 24, 24]          --\n",
       "|    |    Conv2d: 3-552                [-1, 64, 24, 24]          36,864\n",
       "|    |    BatchNorm2d: 3-553           [-1, 64, 24, 24]          128\n",
       "|    |    ReLU: 3-554                  [-1, 64, 24, 24]          --\n",
       "AvgPool2d: 1-10                        [-1, 64, 3, 3]            --\n",
       "Linear: 1-11                           [-1, 256]                 147,712\n",
       "==========================================================================================\n",
       "Total params: 4,406,088\n",
       "Trainable params: 4,406,088\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 3.93\n",
       "==========================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 176.06\n",
       "Params size (MB): 16.81\n",
       "Estimated Total Size (MB): 192.98\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "def conv_res(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual block\n",
    "class res_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(res_block, self).__init__()\n",
    "        self.conv1 = conv_res(in_channels, out_channels, stride)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv_res(out_channels, out_channels)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.bn(self.conv1(x)))\n",
    "        out = self.bn1(self.conv2(out))\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# ResNet\n",
    "class res_net(nn.Module):\n",
    "    def __init__(self, block, layers, triplet=False, num_classes=10):\n",
    "        super(res_net, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.triplet = triplet\n",
    "        self.conv = conv_res(3, 8)\n",
    "        self.conv1 = conv_res(8, 16)\n",
    "        self.bn = nn.BatchNorm2d(8)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.rep_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.rep_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.rep_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc1 = nn.Linear(576, 256)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def rep_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv_res(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward_pass(self,x):\n",
    "        out = self.relu(self.bn(self.conv(x)))\n",
    "        out = self.relu(self.bn1(self.conv1(out)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "#     def dual_pass(self, x1, x2):\n",
    "#         return self.sigmoid(self.forward_pass(x1)), self.sigmoid(self.forward_pass(x2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "       \n",
    "        if self.triplet:\n",
    "\n",
    "            return self.forward_pass(x)\n",
    "        \n",
    "        else:\n",
    "            out = self.relu(self.forward_pass(x))\n",
    "            return self.fc2(out)\n",
    "        \n",
    "    \n",
    "# resnet = res_net(res_block, [4, 16, 16*2], triplet=True, num_classes=len(classes))\n",
    "# \n",
    "resnet = res_net(res_block, [8, 36, 48], triplet=True, num_classes=len(classes))\n",
    "from torchsummary import summary\n",
    "summary(resnet,(3,96,96))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "wErXEqnGB0ZL",
    "outputId": "6fc145e8-aa18-4018-9ab3-711cc850c0e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mneuronics\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">feasible-thunder-13</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/neuronics/uncategorized\" target=\"_blank\">https://wandb.ai/neuronics/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/neuronics/uncategorized/runs/372xbyas\" target=\"_blank\">https://wandb.ai/neuronics/uncategorized/runs/372xbyas</a><br/>\n",
       "                Run data is saved locally in <code>/data/sathya/viper/wandb/run-20210725_001931-372xbyas</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name         | Type              | Params\n",
      "---------------------------------------------------\n",
      "0 | model        | res_net           | 4.4 M \n",
      "1 | accuracy     | Accuracy          | 0     \n",
      "2 | triplet_loss | TripletMarginLoss | 0     \n",
      "3 | fc2          | Linear            | 16.4 K\n",
      "4 | fc3          | Linear            | 325   \n",
      "5 | relu         | ReLU              | 0     \n",
      "---------------------------------------------------\n",
      "4.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.693    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-08.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f2ef3570244f949ea0ae8ce543cbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.4473e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.5492e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0611e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.4549e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.5451e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.9389e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.0451e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.7553e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.7553e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.0451e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.9389e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.5451e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.4549e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0611e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.5492e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.4473e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-08.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.4473e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.5492e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0611e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.4549e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.5451e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.9389e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.0451e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.7553e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.7553e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.0451e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.9389e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.5451e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.4549e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0611e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.5492e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.4473e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-08.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.4473e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.5492e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0611e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.4549e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.5451e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.9389e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.0451e-03.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback_cn = ModelCheckpoint(\n",
    "        monitor='train_loss',\n",
    "        mode = 'min',\n",
    "        save_last=True,\n",
    "        dirpath='weights/triplet_loss',\n",
    "        filename='CE_loss-{epoch:02d}-{train_loss:.8f}'\n",
    "    )\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='valid_acc',\n",
    "        mode = 'max',\n",
    "        save_last=True,\n",
    "        dirpath='weights/triplet_loss+focal/256_CE_8,36,48-P',\n",
    "        filename='CE_loss-{epoch:02d}-{valid_acc:.3f}'\n",
    "    )\n",
    "import wandb\n",
    "wandb.init()\n",
    "\n",
    "wandb.watch(resnet)\n",
    "import ipdb\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = 1.\n",
    "        self.eps = 1e-9\n",
    "\n",
    "    def forward(self, output1, output2, target, size_average=True):\n",
    "        distances = (output2 - output1).pow(2).sum(1)  # squared distances\n",
    "        losses = 0.5 * (float(target) * distances +\n",
    "                        float(1 + -1 * target) * F.relu(self.margin - (distances + self.eps).sqrt()).pow(2))\n",
    "        return losses.mean() if size_average else losses.sum()\n",
    "    \n",
    "contrastive_loss = ContrastiveLoss()\n",
    "\n",
    "class Net(pl.LightningModule):\n",
    "    def __init__(self, model, triplet=False):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "        self.triplet = triplet\n",
    "        self.triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 5)\n",
    "        self.alpha = 1\n",
    "        self.gamma = 2\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x1, x2=None):\n",
    "        if self.triplet:\n",
    "            embedding1 = self.model(x1)\n",
    "            embedding2 = self.model(x2)\n",
    "            return embedding1, embedding2\n",
    "        \n",
    "        else:\n",
    "\n",
    "            embedding = self.model(x1)\n",
    "            return embedding\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = SWA(torch.optim.Adam(self.model.parameters(),  lr=1e-8))\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer,\n",
    "                                                                    T_max=10,\n",
    "                                                                    eta_min=1e-2,\n",
    "                                                                    verbose=True)\n",
    "\n",
    "        return {'optimizer': self.optimizer, 'lr_scheduler': self.scheduler}\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        if self.triplet:\n",
    "            (anc,lab_anc),(pos,lab_pos),(neg,lab_neg) = train_batch\n",
    "           \n",
    "            z_anc = self.model(anc)\n",
    "            z_pos = self.model(pos)\n",
    "            z_neg = self.model(neg)\n",
    "            cont_pos = contrastive_loss(z_anc, z_pos, 1)\n",
    "            cont_neg = contrastive_loss(z_anc, z_neg, 0)\n",
    "            \n",
    "            \n",
    "            z = self.fc2(self.relu(z_anc))\n",
    "            z = self.fc3(self.relu(z))\n",
    "\n",
    "           #Contrastive Loss\n",
    "\n",
    "    \n",
    "            \n",
    "            \n",
    "            CE_loss = F.cross_entropy(z,lab_anc)\n",
    "            pt = torch.exp(-CE_loss)\n",
    "            F_loss = self.alpha * (1-pt)**self.gamma * CE_loss\n",
    "            \n",
    "            loss = self.triplet_loss(z_anc, z_pos, z_neg) + F_loss# + cont_pos + cont_neg\n",
    "            acc = self.accuracy(z, lab_anc)\n",
    "            logs = {'train_loss': loss,'train_acc':acc , 'lr': self.optimizer.param_groups[0]['lr']}\n",
    "            self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "            return loss\n",
    "\n",
    "        \n",
    "        else:\n",
    "            x, y = train_batch\n",
    "            z = self.relu(self.model(x))\n",
    "            z = self.relu(self.fc2(z))\n",
    "            z = self.fc3(z)\n",
    "            loss = F.cross_entropy(z,y)\n",
    "            acc = self.accuracy(z, y)\n",
    "            logs = {'train_loss': loss, 'train_acc': acc, 'lr': self.optimizer.param_groups[0]['lr']}\n",
    "            self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "            return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "\n",
    "            x, y = val_batch\n",
    "            z = self.relu(self.model(x))\n",
    "            z = self.fc2(z)\n",
    "            z = self.fc3(self.relu(z))\n",
    "            loss = F.cross_entropy(z, y)\n",
    "            acc = self.accuracy(z, y)\n",
    "            logs = {'valid_loss': loss, 'valid_acc': acc}\n",
    "            self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "            wandb.log({\"valid_acc\": acc})\n",
    "            return loss\n",
    "  \n",
    "    def training_epoch_end(self, outs):\n",
    "        self.log('train_acc_epoch', self.accuracy.compute())\n",
    "\n",
    "# model\n",
    "model = Net(resnet, triplet=config.triplet)\n",
    "\n",
    "# training\n",
    "trainer = pl.Trainer(gpus=1,precision=16, max_epochs=600, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model, train_dataloader_triplet, val_dataloader)\n",
    "    \n",
    "    \n",
    "    # Have removed brightness augmentor run again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Train Final Classification Layers\n",
    "\n",
    "\n",
    "\n",
    "class final_net(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(final_net, self).__init__()\n",
    "        self.model = model\n",
    "#         self.accuracy = torchmetrics.Accuracy()\n",
    "#         self.triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "#         self.fc2 = nn.Linear(576, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "#         out = self.fc2(out)              #Without ReLU\n",
    "#         out = self.fc2(nn.ReLU(out))\n",
    "        out = self.fc2(self.relu(out))\n",
    "        out = self.fc3(self.relu(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "    \n",
    "FN = final_net(resnet)\n",
    "chkpoint = torch.load('./weights/triplet_loss+focal/128/CE_loss-epoch=330-valid_acc=0.757.ckpt')['state_dict']\n",
    "\n",
    "FN.load_state_dict(chkpoint)\n",
    "\n",
    "# from torchsummary import summary\n",
    "summary(FN,(3,96,96))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in FN.named_parameters():\n",
    "#     if \"fc2\" not in name:\n",
    "# #         print(name)\n",
    "#         param.requires_grad = False\n",
    "# #     params.append(param.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class Net(pl.LightningModule):\n",
    "#     def __init__(self, model, triplet=False):\n",
    "#         super().__init__()\n",
    "#         self.model = model\n",
    "#         self.accuracy = torchmetrics.Accuracy()\n",
    "#         self.triplet = triplet\n",
    "#         self.triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "#         self.fc2 = nn.Linear(64, 5)\n",
    "#         self.alpha = 1\n",
    "#         self.gamma = 2\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x1, x2=None):\n",
    "      \n",
    "#         embedding = self.model(x1)\n",
    "#         return embedding\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         self.optimizer = SWA(torch.optim.Adam(self.model.parameters(),  lr=1e-8))\n",
    "#         self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer,\n",
    "#                                                                     T_max=10,\n",
    "#                                                                     eta_min=1e-2,\n",
    "#                                                                     verbose=True)\n",
    "\n",
    "#         return {'optimizer': self.optimizer, 'lr_scheduler': self.scheduler}\n",
    "\n",
    "#     def training_step(self, train_batch, batch_idx):\n",
    "#             x, y = train_batch\n",
    "#             z = self.model(x)\n",
    "#             loss = F.cross_entropy(z,y)\n",
    "#             acc = self.accuracy(z, y)\n",
    "#             logs = {'train_loss': loss, 'train_acc': acc, 'lr': self.optimizer.param_groups[0]['lr']}\n",
    "#             self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "#             return loss\n",
    "\n",
    "#     def validation_step(self, val_batch, batch_idx):\n",
    "\n",
    "#             x, y = val_batch\n",
    "#             z = self.model(x)\n",
    "# #             z = self.fc2(z)\n",
    "#             loss = F.cross_entropy(z, y)\n",
    "#             acc = self.accuracy(z, y)\n",
    "#             logs = {'valid_loss': loss, 'valid_acc': acc}\n",
    "#             self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "#             return loss\n",
    "  \n",
    "#     def training_epoch_end(self, outs):\n",
    "#         self.log('train_acc_epoch', self.accuracy.compute())\n",
    "\n",
    "# # model\n",
    "# model = Net(FN, triplet=False)\n",
    "\n",
    "# # training\n",
    "# trainer = pl.Trainer(gVanilla-Copy1pus=1,precision=16, max_epochs=400, callbacks=[checkpoint_callback])\n",
    "# trainer.fit(model, train_dataloader, val_dataloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import nn\n",
    "# from torch.nn import functional as F\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch.utils.data import random_split\n",
    "# from torchvision.datasets import MNIST\n",
    "# from torchvision import transforms\n",
    "# import pytorch_lightning as pl\n",
    "# import torchmetrics\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "# def conv_res(in_channels, out_channels, stride=1):\n",
    "#     return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "#                      stride=stride, padding=1, bias=False)\n",
    "\n",
    "# # Residual block\n",
    "# class res_block(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "#         super(res_block, self).__init__()\n",
    "#         self.conv1 = conv_res(in_channels, out_channels, stride)\n",
    "#         self.bn = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.conv2 = conv_res(out_channels, out_channels)\n",
    "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "#         self.downsample = downsample\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         residual = x\n",
    "#         out = self.relu(self.bn(self.conv1(x)))\n",
    "#         out = self.bn1(self.conv2(out))\n",
    "#         if self.downsample:\n",
    "#             residual = self.downsample(x)\n",
    "#         out += residual\n",
    "#         out = self.relu(out)\n",
    "#         return out\n",
    "\n",
    "# # ResNet\n",
    "# class res_net(nn.Module):\n",
    "#     def __init__(self, block, layers, triplet=False, num_classes=10):\n",
    "#         super(res_net, self).__init__()\n",
    "#         self.in_channels = 16\n",
    "#         self.triplet = triplet\n",
    "#         self.conv = conv_res(3, 8)\n",
    "#         self.conv1 = conv_res(8, 16)\n",
    "#         self.bn = nn.BatchNorm2d(8)\n",
    "#         self.bn1 = nn.BatchNorm2d(16)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.layer1 = self.rep_layer(block, 16, layers[0])\n",
    "#         self.layer2 = self.rep_layer(block, 32, layers[1], 2)\n",
    "#         self.layer3 = self.rep_layer(block, 64, layers[2], 2)\n",
    "#         self.avg_pool = nn.AvgPool2d(8)\n",
    "#         self.fc1 = nn.Linear(576, 64)\n",
    "#         self.fc2 = nn.Linear(64, num_classes)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "#     def rep_layer(self, block, out_channels, blocks, stride=1):\n",
    "#         downsample = None\n",
    "#         if (stride != 1) or (self.in_channels != out_channels):\n",
    "#             downsample = nn.Sequential(\n",
    "#                 conv_res(self.in_channels, out_channels, stride=stride),\n",
    "#                 nn.BatchNorm2d(out_channels))\n",
    "#         layers = []\n",
    "#         layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "#         self.in_channels = out_channels\n",
    "#         for i in range(1, blocks):\n",
    "#             layers.append(block(out_channels, out_channels))\n",
    "#         return nn.Sequential(*layers)\n",
    "    \n",
    "#     def forward_pass(self,x):\n",
    "#         out = self.relu(self.bn(self.conv(x)))\n",
    "#         out = self.relu(self.bn1(self.conv1(out)))\n",
    "#         out = self.layer1(out)\n",
    "#         out = self.layer2(out)\n",
    "#         out = self.layer3(out)\n",
    "#         out = self.avg_pool(out)\n",
    "#         out = out.view(out.size(0), -1)\n",
    "#         out = self.fc1(out)\n",
    "        \n",
    "#         return out\n",
    "    \n",
    "# #     def dual_pass(self, x1, x2):\n",
    "# #         return self.sigmoid(self.forward_pass(x1)), self.sigmoid(self.forward_pass(x2))\n",
    "        \n",
    "#     def forward(self, x):\n",
    "       \n",
    "#         if self.triplet:\n",
    "\n",
    "#             return self.forward_pass(x)\n",
    "        \n",
    "#         else:\n",
    "#             out = self.relu(self.forward_pass(x))\n",
    "#             return self.fc2(out)\n",
    "        \n",
    "    \n",
    "# resnet = res_net(res_block, [4, 16, 16*2], triplet=True, num_classes=5)\n",
    "\n",
    "\n",
    "\n",
    "# class final_net(nn.Module):\n",
    "#     def __init__(self, model):\n",
    "#         super(final_net, self).__init__()\n",
    "#         self.model = model\n",
    "#         self.accuracy = torchmetrics.Accuracy()\n",
    "#         self.triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "#         self.fc2 = nn.Linear(64, 5)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out = self.model(x)\n",
    "#         out = self.fc2(out)              #Without ReLU\n",
    "# #         out = self.fc2(nn.ReLU(out))\n",
    "#         return out\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# FN = final_net(resnet).to(device)\n",
    "# FN.load_state_dict(torch.load('./weights/triplet_loss+focal/vanilla/CE_loss-epoch=151-valid_acc=0.738.ckpt')['state_dict'])\n",
    "\n",
    "# from torchsummary import summary\n",
    "# summary(FN,(3,96,96))\n",
    "\n",
    "# model  = FN.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# targets, preds = [], []\n",
    "\n",
    "# train_transform = A.Compose(\n",
    "#     [\n",
    "# #        A.ShiftScaleRotate(rotate_limit=(-360, 360), shift_limit=(0.1, 0.12), scale_limit=(0.1, 0.12)),\n",
    "# #        A.HorizontalFlip(p=0.6),\n",
    "# #        A.Rotate (limit=120),\n",
    "# #        A.Perspective(scale=(0.05, 0.1)),\n",
    "# #        A.Affine (scale=1,translate_percent=0.1,rotate=40,cval=0.90,fit_output=True),\n",
    "#        ToTensorV2(),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# valid_transform = A.Compose(\n",
    "#     [\n",
    "#        ToTensorV2(),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# val_dataset = vdataset(val_df, transform = valid_transform)\n",
    "\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=8*4,\n",
    "#                         shuffle=False, num_workers=32)\n",
    "\n",
    "# for batch_idx, data in tqdm(enumerate(val_dataloader)):\n",
    "#     x, y = data\n",
    "#     targets.append(y)\n",
    "#     predictions = model(x.to(device))\n",
    "#     preds.append(torch.argmax(predictions,axis=1).cpu().detach().numpy())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.asarray(torch.argmax(predictions,axis=1).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets = np.asarray(targets)\n",
    "# preds = np.asarray(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Robet Bosch Viper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
