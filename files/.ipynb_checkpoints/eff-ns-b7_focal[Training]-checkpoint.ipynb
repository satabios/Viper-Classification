{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# %pip install timm\n",
    "# %pip install torchcontrib\n",
    "import os\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold\n",
    "from torchvision import transforms as tsfm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.metrics import Metric\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    root_dir_origin = \"./data\"\n",
    "    train_csv_path = os.path.join(root_dir_origin, 'train.csv')\n",
    "    train_imgs_dir = os.path.join(root_dir_origin, 'train_images/')\n",
    "    # data info\n",
    "    label_num2str = {0: 'powdery_mildew',\n",
    "                     1: 'scab',\n",
    "                     2: 'complex',\n",
    "                     3: 'frog_eye_leaf_spot',\n",
    "                     4: 'rust'}\n",
    "    \n",
    "    label_str2num = {'powdery_mildew': 0,\n",
    "                     'scab': 1,\n",
    "                     'complex': 2,\n",
    "                     'frog_eye_leaf_spot': 3,\n",
    "                     'rust': 4}\n",
    "    # model info\n",
    "    model_name = 'tf_efficientnet_b7_ns'\n",
    "    # training hyper-parameters\n",
    "    fl_alpha = 1.0  # alpha of focal_loss\n",
    "    fl_gamma = 2.0  # gamma of focal_loss\n",
    "    use_swa = True\n",
    "    seed = 77\n",
    "    num_classes = 5\n",
    "    num_epochs = 30\n",
    "    batch_size = 2\n",
    "    t_max = 3\n",
    "    lr = 7e-4\n",
    "    min_lr = 1e-6\n",
    "    n_fold = 6\n",
    "    num_workers = 16\n",
    "    accum_grad_batch = 1\n",
    "    early_stop_delta = 1e-7\n",
    "    device = torch.device('cuda')# if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates.csv  sample_submission.csv  train.csv  \u001b[0m\u001b[01;34mtrain_images\u001b[0m/  train_orig.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "      <th>numerical labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800113bb65efe69e.jpg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8002cb321f8bfcdf.jpg</td>\n",
       "      <td>scab frog_eye_leaf_spot complex</td>\n",
       "      <td>[1, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80070f7fb5e2ccaa.jpg</td>\n",
       "      <td>scab</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80077517781fb94f.jpg</td>\n",
       "      <td>scab</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800cbf0ff87721f8.jpg</td>\n",
       "      <td>complex</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18627</th>\n",
       "      <td>fffb900a92289a33.jpg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18628</th>\n",
       "      <td>fffc488fa4c0e80c.jpg</td>\n",
       "      <td>scab</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18629</th>\n",
       "      <td>fffc94e092a59086.jpg</td>\n",
       "      <td>rust</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18630</th>\n",
       "      <td>fffe105cf6808292.jpg</td>\n",
       "      <td>scab frog_eye_leaf_spot</td>\n",
       "      <td>[1, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18631</th>\n",
       "      <td>fffe472a0001bd25.jpg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18632 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      image                           labels numerical labels\n",
       "0      800113bb65efe69e.jpg                          healthy               []\n",
       "1      8002cb321f8bfcdf.jpg  scab frog_eye_leaf_spot complex        [1, 3, 2]\n",
       "2      80070f7fb5e2ccaa.jpg                             scab              [1]\n",
       "3      80077517781fb94f.jpg                             scab              [1]\n",
       "4      800cbf0ff87721f8.jpg                          complex              [2]\n",
       "...                     ...                              ...              ...\n",
       "18627  fffb900a92289a33.jpg                          healthy               []\n",
       "18628  fffc488fa4c0e80c.jpg                             scab              [1]\n",
       "18629  fffc94e092a59086.jpg                             rust              [4]\n",
       "18630  fffe105cf6808292.jpg          scab frog_eye_leaf_spot           [1, 3]\n",
       "18631  fffe472a0001bd25.jpg                          healthy               []\n",
       "\n",
       "[18632 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Add numerical labels for dataframe\n",
    "\"\"\"\n",
    "TRAIN_DF = pd.read_csv(CFG.train_csv_path)\n",
    "\n",
    "all_numeric_labels = []\n",
    "for row_idx, row in TRAIN_DF.iterrows():\n",
    "    labels_list = row['labels'].split(\" \")\n",
    "    numeric_label_list = [CFG.label_str2num[each] for each in labels_list if each != 'healthy']\n",
    "    all_numeric_labels.append(numeric_label_list)\n",
    "TRAIN_DF['numerical labels'] = all_numeric_labels\n",
    "TRAIN_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define train & valid image transformation\n",
    "\"\"\"\n",
    "DATASET_IMAGE_MEAN = (0.485, 0.456, 0.406)\n",
    "DATASET_IMAGE_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_transform = tsfm.Compose([tsfm.RandomApply([tsfm.ColorJitter(0.2, 0.2, 0.2),tsfm.RandomPerspective(distortion_scale=0.2),], p=0.3),\n",
    "                                tsfm.RandomApply([tsfm.ColorJitter(0.2, 0.2, 0.2),tsfm.RandomAffine(degrees=10),], p=0.3),\n",
    "                                tsfm.RandomVerticalFlip(p=0.3),\n",
    "                                tsfm.RandomHorizontalFlip(p=0.3),\n",
    "                                tsfm.ToTensor(),\n",
    "                                tsfm.Normalize(DATASET_IMAGE_MEAN, DATASET_IMAGE_STD), ])\n",
    "\n",
    "valid_transform = tsfm.Compose([tsfm.ToTensor(),\n",
    "                                tsfm.Normalize(DATASET_IMAGE_MEAN, DATASET_IMAGE_STD), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define dataset class\n",
    "\"\"\"\n",
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, cfg, img_names: list, labels: list, transform=None):\n",
    "        self.img_dir = cfg.train_imgs_dir\n",
    "        self.img_names = img_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "#         return int(10)\n",
    "        return len(self.img_names)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = img.resize((600,600))\n",
    "        img_ts = self.transform(img)\n",
    "        label_ts = self.labels[idx]\n",
    "        return img_ts, label_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Focal-Loss\n",
    "\"\"\"\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    The focal loss for fighting against class-imbalance\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = 1e-12  # prevent training from Nan-loss error\n",
    "        self.cls_weights = torch.tensor([[0.3648, 0.0813, 0.2184, 0.1066, 0.2290]],dtype=torch.float, requires_grad=False, device=CFG.device)\n",
    "        self.lb_smooth = 0.1\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        \"\"\"\n",
    "        logits & target should be tensors with shape [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(logits)\n",
    "        one_subtract_probs = 1.0 - probs\n",
    "        # add epsilon\n",
    "        probs_new = probs + self.epsilon\n",
    "        one_subtract_probs_new = one_subtract_probs + self.epsilon\n",
    "        # calculate focal loss\n",
    "        target = torch.abs(target - self.lb_smooth)\n",
    "        log_pt = target * torch.log(probs_new) + (1.0 - target) * torch.log(one_subtract_probs_new)\n",
    "        pt = torch.exp(log_pt)\n",
    "        focal_loss = -1.0 * (self.alpha * (1 - pt) ** self.gamma) * log_pt\n",
    "        focal_loss = focal_loss * self.cls_weights\n",
    "        return torch.mean(focal_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define F1 score metric\n",
    "\"\"\"\n",
    "class MyF1Score(Metric):\n",
    "    def __init__(self, cfg, threshold: float = 0.5, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        self.cfg = cfg\n",
    "        self.threshold = threshold\n",
    "        self.add_state(\"tp\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"fp\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"fn\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        assert preds.shape == target.shape\n",
    "        preds_str_batch = self.num_to_str(torch.sigmoid(preds))\n",
    "        target_str_batch = self.num_to_str(target)\n",
    "        tp, fp, fn = 0, 0, 0\n",
    "        for pred_str_list, target_str_list in zip(preds_str_batch, target_str_batch):\n",
    "            for pred_str in pred_str_list:\n",
    "                if pred_str in target_str_list:\n",
    "                    tp += 1\n",
    "                if pred_str not in target_str_list:\n",
    "                    fp += 1\n",
    "\n",
    "            for target_str in target_str_list:\n",
    "                if target_str not in pred_str_list:\n",
    "                    fn += 1\n",
    "        self.tp += tp\n",
    "        self.fp += fp\n",
    "        self.fn += fn\n",
    "\n",
    "    def compute(self):\n",
    "        f1 = 2.0 * self.tp / (2.0 * self.tp + self.fn + self.fp)\n",
    "        return f1\n",
    "    \n",
    "    def num_to_str(self, ts: torch.Tensor) -> list:\n",
    "        batch_bool_list = (ts > self.threshold).detach().cpu().numpy().tolist()\n",
    "        batch_str_list = []\n",
    "        for one_sample_bool in batch_bool_list:\n",
    "            lb_str_list = [self.cfg.label_num2str[lb_idx] for lb_idx, bool_val in enumerate(one_sample_bool) if bool_val]\n",
    "            if len(lb_str_list) == 0:\n",
    "                lb_str_list = ['healthy']\n",
    "            batch_str_list.append(lb_str_list)\n",
    "        return batch_str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define neural network model\n",
    "\"\"\"\n",
    "\n",
    "class MyNetwork(pl.LightningModule):\n",
    "    def __init__(self, cfg):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.model = timm.create_model(cfg.model_name, pretrained=True, num_classes=cfg.num_classes)\n",
    "        self.criterion = FocalLoss(cfg.fl_alpha, cfg.fl_gamma)\n",
    "        self.metric = MyF1Score(cfg)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        if self.cfg.use_swa:\n",
    "            self.optimizer = SWA(torch.optim.Adam(self.model.parameters(), lr=self.cfg.lr))\n",
    "        else:\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.cfg.lr)\n",
    "            \n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer,\n",
    "                                                                    T_max=self.cfg.t_max,\n",
    "                                                                    eta_min=self.cfg.min_lr,\n",
    "                                                                    verbose=True)\n",
    "        return {'optimizer': self.optimizer, 'lr_scheduler': self.scheduler}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img_ts, lb_ts = batch\n",
    "        pred_ts = self.model(img_ts)\n",
    "        loss = self.criterion(pred_ts, lb_ts)\n",
    "        score = self.metric(pred_ts, lb_ts)\n",
    "        logs = {'train_loss': loss, 'train_f1': score, 'lr': self.optimizer.param_groups[0]['lr']}\n",
    "        self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img_ts, lb_ts = batch\n",
    "        pred_ts = self.model(img_ts)\n",
    "        loss = self.criterion(pred_ts, lb_ts)\n",
    "        score = self.metric(pred_ts, lb_ts)\n",
    "        logs = {'valid_loss': loss, 'valid_f1': score}\n",
    "        self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Befor reomve duplicates: 18632 ,  18632\n",
      "Num of duplicated samples:  98\n",
      "After reomve duplicates: 18534 ,  18534\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split train & validation into Cross-Validation Folds\n",
    "\"\"\"\n",
    "\n",
    "all_img_names: list = TRAIN_DF[\"image\"].values.tolist()\n",
    "all_img_labels: list = TRAIN_DF[\"numerical labels\"].values.tolist()\n",
    "print(\"Befor reomve duplicates:\", len(all_img_names), \", \", len(all_img_labels))\n",
    "    \n",
    "\"\"\"\n",
    "Remove duplicated samples from the training image\n",
    "\"\"\"\n",
    "dplct_csv_path = \"./data/duplicates.csv\"\n",
    "dplct_pd = pd.read_csv(dplct_csv_path)\n",
    "dplct_img_names = dplct_pd.iloc[:, 0].values.tolist() + dplct_pd.iloc[:, 1].values.tolist()\n",
    "dplct_img_names = list(set(dplct_img_names))\n",
    "print(\"Num of duplicated samples: \", len(dplct_img_names))\n",
    "\n",
    "img_names_no_dplct = []\n",
    "img_labels_no_dplct = []\n",
    "for img_name, img_label in zip(all_img_names, all_img_labels):\n",
    "    if img_name not in dplct_img_names:\n",
    "        img_names_no_dplct.append(img_name)\n",
    "        img_labels_no_dplct.append(img_label)\n",
    "        \n",
    "all_img_names = img_names_no_dplct\n",
    "all_img_labels = img_labels_no_dplct\n",
    "print(\"After reomve duplicates:\", len(all_img_names), \", \", len(all_img_labels))\n",
    "    \n",
    "all_img_labels_ts = []\n",
    "for tmp_lb in all_img_labels:\n",
    "    tmp_label = torch.zeros([CFG.num_classes], dtype=torch.float)\n",
    "    for idx in tmp_lb:\n",
    "        tmp_label[idx] = 1.0\n",
    "    all_img_labels_ts.append(tmp_label)\n",
    "    \n",
    "k_fold = KFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/sathya/anaconda3/envs/hpa/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:402: UserWarning: Skipping '__dict__' parameter because it is not possible to safely dump to YAML.\n",
      "  warn(f\"Skipping '{k}' parameter because it is not possible to safely dump to YAML.\")\n",
      "/home/sathya/anaconda3/envs/hpa/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:402: UserWarning: Skipping '__weakref__' parameter because it is not possible to safely dump to YAML.\n",
      "  warn(f\"Skipping '{k}' parameter because it is not possible to safely dump to YAML.\")\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | model     | EfficientNet | 63.8 M\n",
      "1 | criterion | FocalLoss    | 0     \n",
      "2 | metric    | MyF1Score    | 0     \n",
      "-------------------------------------------\n",
      "63.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "63.8 M    Total params\n",
      "255.199   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 77\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f88d758b8b247dea4bbf9bf99262850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2525e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7575e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7575e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2525e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2525e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7575e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7575e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2525e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2525e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7575e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7575e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2525e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2525e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7575e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7575e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2525e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2525e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7575e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7575e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2525e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | model     | EfficientNet | 63.8 M\n",
      "1 | criterion | FocalLoss    | 0     \n",
      "2 | metric    | MyF1Score    | 0     \n",
      "-------------------------------------------\n",
      "63.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "63.8 M    Total params\n",
      "255.199   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 77\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8861306f204a89aa3361986a02c5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sathya/anaconda3/envs/hpa/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | model     | EfficientNet | 63.8 M\n",
      "1 | criterion | FocalLoss    | 0     \n",
      "2 | metric    | MyF1Score    | 0     \n",
      "-------------------------------------------\n",
      "63.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "63.8 M    Total params\n",
      "255.199   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 77\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a75e05a84a64a5aba865b15ec08b7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "# if os.path.isdir(\"./model_log/\")==False:\n",
    "    \n",
    "#     os.mkdir(\"./model_logs/\")\n",
    "\n",
    "for fold_idx, (train_indices, valid_indices) in enumerate(k_fold.split(all_img_names)):\n",
    "    \"\"\"\n",
    "    Init trainer\n",
    "    \"\"\"\n",
    "    logger = CSVLogger(save_dir=f'model_logs/fold{fold_idx}_logs/', name=CFG.model_name)\n",
    "    logger.log_hyperparams(CFG.__dict__)\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='valid_f1',\n",
    "                                          save_top_k=3,\n",
    "                                          save_last=True,\n",
    "                                          save_weights_only=True,\n",
    "#                                           dirpath='./',\n",
    "                                          filename='best_perform',\n",
    "                                          verbose=False,\n",
    "                                          mode='max')\n",
    "    \n",
    "#     checkpoint_callback = ModelCheckpoint(\n",
    "#     monitor='val_loss',\n",
    "#     dirpath='my/path/',\n",
    "#     filename='best',\n",
    "#     save_top_k=3,\n",
    "#     mode='max',)\n",
    "\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(monitor='valid_loss', min_delta=CFG.early_stop_delta, patience=4, mode='min')\n",
    "#     trainer = Trainer()\n",
    "    trainer = Trainer(max_epochs=CFG.num_epochs,\n",
    "                      gpus=1,\n",
    "                      accumulate_grad_batches=CFG.accum_grad_batch,\n",
    "                      callbacks=checkpoint_callback,\n",
    "#                       callbacks=[],\n",
    "#                       checkpoint_callback=checkpoint_callback,\n",
    "                      logger=logger,\n",
    "                      weights_summary='top',)\n",
    "    \"\"\"\n",
    "    Init dataset & dataloader\n",
    "    \"\"\"\n",
    "    # get image names and labels\n",
    "    fold_train_img_names = [all_img_names[idx] for idx in train_indices]\n",
    "    fold_valid_img_names = [all_img_names[idx] for idx in valid_indices]\n",
    "    fold_train_img_labels = [all_img_labels_ts[idx] for idx in train_indices]\n",
    "    fold_valid_img_labels = [all_img_labels_ts[idx] for idx in valid_indices]\n",
    "    # dataset\n",
    "    train_dataset = PlantDataset(CFG, fold_train_img_names, fold_train_img_labels, train_transform)\n",
    "    valid_dataset = PlantDataset(CFG, fold_valid_img_names, fold_valid_img_labels, valid_transform)\n",
    "    # dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Init model\n",
    "    \"\"\"\n",
    "    model = MyNetwork(CFG)#.load_from_checkpoint('/media/14tb/sathya/leafr/final.ckpt', cfg=CFG)\n",
    "    \n",
    "    \"\"\"\n",
    "    Fit(train) the model\n",
    "    \"\"\"\n",
    "    trainer.fit(model, train_dataloader=train_loader, val_dataloaders=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot training results\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(32, 10), constrained_layout=True)\n",
    "gs = gridspec.GridSpec(2, CFG.n_fold, figure=fig)\n",
    "\n",
    "\n",
    "for fold_idx in range(CFG.n_fold):\n",
    "    tmp_log_dir = f\"fold{fold_idx}_logs/{CFG.model_name}/version_0\"\n",
    "    metrics = pd.read_csv(os.path.join(tmp_log_dir, 'metrics.csv'))\n",
    "\n",
    "    train_acc = metrics['train_f1'].dropna().reset_index(drop=True)\n",
    "    valid_acc = metrics['valid_f1'].dropna().reset_index(drop=True)\n",
    "    \n",
    "    ax = fig.add_subplot(gs[0, fold_idx])\n",
    "    ax.plot(train_acc, color=\"r\", marker=\"o\", label='train/f1')\n",
    "    ax.plot(valid_acc, color=\"b\", marker=\"x\", label='valid/f1')\n",
    "    ax.set_xlabel('Epoch', fontsize=24)\n",
    "    ax.set_ylabel('F1', fontsize=24)\n",
    "    ax.set_title(f'fold {fold_idx}')\n",
    "    ax.legend(loc='lower right', fontsize=18)\n",
    "\n",
    "\n",
    "    train_loss = metrics['train_loss'].dropna().reset_index(drop=True)\n",
    "    valid_loss = metrics['valid_loss'].dropna().reset_index(drop=True)\n",
    "\n",
    "    ax = fig.add_subplot(gs[1, fold_idx])\n",
    "    ax.plot(train_loss, color=\"r\", marker=\"o\", label='train/loss')\n",
    "    ax.plot(valid_loss, color=\"b\", marker=\"x\", label='valid/loss')\n",
    "    ax.set_ylabel('Loss', fontsize=24)\n",
    "    ax.set_xlabel('Epoch', fontsize=24)\n",
    "    ax.legend(loc='upper right', fontsize=18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
